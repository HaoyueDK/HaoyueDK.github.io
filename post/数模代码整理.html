<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>数模代码整理 | HaoyueDK</title><meta name="author" content="浩月当空"><meta name="copyright" content="浩月当空"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="绘图类 python绘图 调用 python matplotlib.pyplot库进行绘制，除如下列举的例子外，其余可参考：Matplotlib绘图详解  折线图 12345678import matplotlib.pyplot as pltimport numpy as npxpoints &#x3D; np.array([1, 8])ypoints &#x3D; np.array([3, 10])plt.plot">
<meta property="og:type" content="article">
<meta property="og:title" content="数模代码整理">
<meta property="og:url" content="http://example.com/post/%E6%95%B0%E6%A8%A1%E4%BB%A3%E7%A0%81%E6%95%B4%E7%90%86.html">
<meta property="og:site_name" content="HaoyueDK">
<meta property="og:description" content="绘图类 python绘图 调用 python matplotlib.pyplot库进行绘制，除如下列举的例子外，其余可参考：Matplotlib绘图详解  折线图 12345678import matplotlib.pyplot as pltimport numpy as npxpoints &#x3D; np.array([1, 8])ypoints &#x3D; np.array([3, 10])plt.plot">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://s1.ax1x.com/2023/01/05/pSAEFZd.jpg">
<meta property="article:published_time" content="2024-08-31T16:00:00.000Z">
<meta property="article:modified_time" content="2024-09-01T08:11:59.190Z">
<meta property="article:author" content="浩月当空">
<meta property="article:tag" content="数学建模">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s1.ax1x.com/2023/01/05/pSAEFZd.jpg"><link rel="shortcut icon" href="https://s1.ax1x.com/2023/01/05/pSAFTYV.png"><link rel="canonical" href="http://example.com/post/%E6%95%B0%E6%A8%A1%E4%BB%A3%E7%A0%81%E6%95%B4%E7%90%86"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":100},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '数模代码整理',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-09-01 16:11:59'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/cursor.css"><link rel="stylesheet" href="/css/footercolor.css"><link rel="stylesheet" href="/css/scrollbar.css"><link rel="stylesheet" href="/css/transparency.css"><meta name="generator" content="Hexo 6.3.0"><link href="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.css" rel="stylesheet" /></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://s1.ax1x.com/2023/01/05/pSAFoF0.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">30</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">19</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">17</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://s1.ax1x.com/2023/01/05/pSAEFZd.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">HaoyueDK</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">数模代码整理</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-08-31T16:00:00.000Z" title="发表于 2024-09-01 00:00:00">2024-09-01</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-09-01T08:11:59.190Z" title="更新于 2024-09-01 16:11:59">2024-09-01</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/">数学建模</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="数模代码整理"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h2 id="绘图类">绘图类</h2>
<h3 id="python绘图">python绘图</h3>
<p>调用 python matplotlib.pyplot库进行绘制，除如下列举的例子外，其余可参考：<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_40336702/article/details/125858685">Matplotlib绘图详解<br>
</a></p>
<h4 id="折线图">折线图</h4>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">xpoints = np.array([<span class="number">1</span>, <span class="number">8</span>])</span><br><span class="line">ypoints = np.array([<span class="number">3</span>, <span class="number">10</span>])</span><br><span class="line"></span><br><span class="line">plt.plot(xpoints, ypoints)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h4 id="散点图">散点图</h4>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">xpoints = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">6</span>, <span class="number">8</span>])</span><br><span class="line">ypoints = np.array([<span class="number">3</span>, <span class="number">8</span>, <span class="number">1</span>, <span class="number">10</span>])</span><br><span class="line"></span><br><span class="line">plt.plot(xpoints, ypoints, <span class="string">&#x27;o&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h4 id="饼图">饼图</h4>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>]=[<span class="string">&#x27;Microsoft YaHei&#x27;</span>]  <span class="comment">#显示中文标签,处理中文乱码问题</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>]=<span class="literal">False</span>  <span class="comment">#坐标轴负号的处理</span></span><br><span class="line">plt.axes(aspect=<span class="string">&#x27;equal&#x27;</span>)  <span class="comment">#将横、纵坐标轴标准化处理，确保饼图是一个正圆，否则为椭圆</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#构造数据</span></span><br><span class="line">edu = [<span class="number">0.2515</span>, <span class="number">0.3724</span>, <span class="number">0.3336</span>, <span class="number">0.0368</span>, <span class="number">0.0057</span>]</span><br><span class="line">labels = [<span class="string">&#x27;中专&#x27;</span>,<span class="string">&#x27;大专&#x27;</span>,<span class="string">&#x27;本科&#x27;</span>,<span class="string">&#x27;硕士&#x27;</span>,<span class="string">&#x27;其他&#x27;</span>]</span><br><span class="line">explode = [<span class="number">0</span>, <span class="number">0.1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]  <span class="comment">#生成数据，用于凸显大专学历人群</span></span><br><span class="line">colors = [<span class="string">&#x27;#9999ff&#x27;</span>, <span class="string">&#x27;#ff9999&#x27;</span>, <span class="string">&#x27;#7777aa&#x27;</span>, <span class="string">&#x27;#2442aa&#x27;</span>, <span class="string">&#x27;#dd5555&#x27;</span>]  <span class="comment">#自定义颜色</span></span><br><span class="line"></span><br><span class="line">plt.pie(x=edu,  <span class="comment">#绘图数据</span></span><br><span class="line">        explode=explode, <span class="comment">#指定饼图某些部分的突出显示，即呈现爆炸式</span></span><br><span class="line">        labels=labels,  <span class="comment">#添加教育水平标签</span></span><br><span class="line">        colors=colors,</span><br><span class="line">        autopct=<span class="string">&#x27;%.2f%%&#x27;</span>,  <span class="comment">#设置百分比的格式，这里保留两位小数</span></span><br><span class="line">        pctdistance=<span class="number">0.8</span>,  <span class="comment">#设置百分比标签与圆心的距离</span></span><br><span class="line">        labeldistance=<span class="number">1.1</span>,  <span class="comment">#设置教育水平标签与圆心的距离</span></span><br><span class="line">        startangle=<span class="number">180</span>,  <span class="comment">#设置饼图的初始角度</span></span><br><span class="line">        radius=<span class="number">1.2</span>,  <span class="comment">#设置饼图的半径</span></span><br><span class="line">        counterclock=<span class="literal">False</span>,  <span class="comment">#是否逆时针，这里设置为顺时针方向</span></span><br><span class="line">        wedgeprops=&#123;<span class="string">&#x27;linewidth&#x27;</span>:<span class="number">1.5</span>, <span class="string">&#x27;edgecolor&#x27;</span>:<span class="string">&#x27;green&#x27;</span>&#125;,  <span class="comment">#设置饼图内外边界的属性值</span></span><br><span class="line">        textprops=&#123;<span class="string">&#x27;fontsize&#x27;</span>:<span class="number">10</span>, <span class="string">&#x27;color&#x27;</span>:<span class="string">&#x27;black&#x27;</span>&#125;,  <span class="comment">#设置文本标签的属性值</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line"><span class="comment">#添加图标题</span></span><br><span class="line">plt.title(<span class="string">&#x27;失信用户的受教育水平分布&#x27;</span>)</span><br><span class="line"><span class="comment">#显示图形</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h2 id="数据处理和算法内容">数据处理和算法内容</h2>
<p>在《按赛题类型划分算法及代码（84种）》文件夹内搜索即可。下面列举的是课件内容。</p>
<h3 id="3-1-熵权法">3-1 熵权法</h3>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.family&#x27;</span>]=<span class="string">&#x27;SimHei&#x27;</span></span><br><span class="line">x=pd.read_excel(<span class="string">&#x27;待选材料参数.xlsx&#x27;</span>,engine=<span class="string">&#x27;openpyxl&#x27;</span>).values</span><br><span class="line">x[:,<span class="number">1</span>]=-x[:,<span class="number">1</span>]</span><br><span class="line">x[:,<span class="number">3</span>]=-x[:,<span class="number">3</span>]</span><br><span class="line">x=np.delete(x,-<span class="number">1</span>,axis=<span class="number">0</span>)</span><br><span class="line">x=MinMaxScaler().fit(x).transform(x)</span><br><span class="line">p=x/np.<span class="built_in">sum</span>(x,axis=<span class="number">0</span>)</span><br><span class="line">e=np.zeros(x.shape[<span class="number">1</span>])</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(x.shape[<span class="number">1</span>]):</span><br><span class="line">    sum0=<span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(x.shape[<span class="number">0</span>]):</span><br><span class="line">        <span class="keyword">if</span> p[j,i]==<span class="number">0</span>:</span><br><span class="line">            sum0+=<span class="number">0</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            sum0+=p[j,i]*np.log(p[j,i])</span><br><span class="line">    e[i]=-<span class="number">1</span>/np.log(<span class="number">3</span>)*sum0</span><br><span class="line">w=(<span class="number">1</span>-e)/np.<span class="built_in">sum</span>(<span class="number">1</span>-e)</span><br><span class="line">defen=x@w.reshape(-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">defen=defen.flatten()</span><br><span class="line">a=np.sort(defen)</span><br></pre></td></tr></table></figure>
<h3 id="3-3-改进模拟退火算法">3-3 改进模拟退火算法</h3>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> loadtxt,radians,sin,cos,inf,exp</span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> array,r_,c_,arange,savetxt</span><br><span class="line"><span class="keyword">from</span> numpy.lib.scimath <span class="keyword">import</span> arccos</span><br><span class="line"><span class="keyword">from</span> numpy.random <span class="keyword">import</span> shuffle,randint,rand</span><br><span class="line"><span class="keyword">from</span> matplotlib.pyplot <span class="keyword">import</span> plot, show, rc</span><br><span class="line">d=np.loadtxt(<span class="string">&#x27;各个城市的最短路径.txt&#x27;</span>)</span><br><span class="line"></span><br><span class="line">N=d.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">path=arange(N); L=inf</span><br><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000</span>):</span><br><span class="line">    path0=arange(<span class="number">1</span>,N-<span class="number">1</span>); shuffle(path0)</span><br><span class="line">    path0=r_[<span class="number">0</span>,path0,N-<span class="number">1</span>]; L0=d[<span class="number">0</span>,path0[<span class="number">1</span>]]  <span class="comment">#初始化</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,N-<span class="number">1</span>):L0+=d[path0[i],path0[i+<span class="number">1</span>]]</span><br><span class="line">    <span class="keyword">if</span> L0&lt;L: path=path0; L=L0</span><br><span class="line"><span class="built_in">print</span>(path,<span class="string">&#x27;\n&#x27;</span>,L)        </span><br><span class="line">e=<span class="number">0.1</span>**<span class="number">30</span>; M=<span class="number">20000</span>; at=<span class="number">0.999</span>; T=<span class="number">1</span></span><br><span class="line">gl=np.zeros(N-<span class="number">2</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(N-<span class="number">2</span>):</span><br><span class="line">    gl[i]=d[path[i],path[i+<span class="number">1</span>]]</span><br><span class="line"><span class="keyword">while</span> T&gt;e:</span><br><span class="line">    pl=gl/gl.<span class="built_in">sum</span>()</span><br><span class="line">    c=np.random.choice(a=np.arange(<span class="number">1</span>,N-<span class="number">1</span>),size=<span class="number">2</span>,replace=<span class="literal">False</span>,p=pl)</span><br><span class="line">    c.sort()</span><br><span class="line">    c1=c[<span class="number">0</span>]; c2=c[<span class="number">1</span>]</span><br><span class="line">    df=d[path[c1-<span class="number">1</span>],path[c2]]+d[path[c1],path[c2+<span class="number">1</span>]]-\</span><br><span class="line">    d[path[c1-<span class="number">1</span>],path[c1]]-d[path[c2],path[c2+<span class="number">1</span>]]  <span class="comment">#续行</span></span><br><span class="line">    <span class="keyword">if</span> df&lt;<span class="number">0</span>:</span><br><span class="line">        path=r_[path[<span class="number">0</span>],path[<span class="number">1</span>:c1],path[c2:c1-<span class="number">1</span>:-<span class="number">1</span>],path[c2+<span class="number">1</span>:N+<span class="number">1</span>]]; L=L+df</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(N-<span class="number">2</span>):</span><br><span class="line">            gl[i]=d[path[i],path[i+<span class="number">1</span>]]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">if</span> exp(-df/T)&gt;=rand(<span class="number">1</span>):</span><br><span class="line">            path=r_[path[<span class="number">0</span>],path[<span class="number">1</span>:c1],path[c2:c1-<span class="number">1</span>:-<span class="number">1</span>],path[c2+<span class="number">1</span>:N+<span class="number">1</span>]]</span><br><span class="line">            L=L+df</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(N-<span class="number">2</span>):</span><br><span class="line">                gl[i]=d[path[i],path[i+<span class="number">1</span>]]</span><br><span class="line">    T=T*at</span><br><span class="line"><span class="built_in">print</span>(path,<span class="string">&#x27;\n&#x27;</span>,L)  <span class="comment">#输出巡航路径及路径长度</span></span><br></pre></td></tr></table></figure>
<h3 id="3-3-旅行商问题">3-3 旅行商问题</h3>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> gurobipy <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">mat=np.loadtxt(<span class="string">&#x27;各个城市的最短路径.txt&#x27;</span>)</span><br><span class="line">n=mat.shape[<span class="number">0</span>]</span><br><span class="line">m=Model()</span><br><span class="line">x=m.addVars(n,n,vtype=GRB.BINARY,name=<span class="string">&#x27;x&#x27;</span>)</span><br><span class="line">u=m.addVars(n)</span><br><span class="line">m.setObjective(<span class="built_in">sum</span>(mat[i,j]*x[i,j] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n) <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n) <span class="keyword">if</span> i!=j),GRB.MINIMIZE)</span><br><span class="line">m.addConstrs(<span class="built_in">sum</span>(x[i,j] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n) <span class="keyword">if</span> i!=j)==<span class="number">1</span> <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n))</span><br><span class="line">m.addConstrs(<span class="built_in">sum</span>(x[i,j] <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n) <span class="keyword">if</span> i!=j)==<span class="number">1</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n))</span><br><span class="line">m.addConstrs(u[i]-u[j]+n*x[i,j]&lt;=n-<span class="number">1</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,n) <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,n) <span class="keyword">if</span> i!=j)</span><br><span class="line">m.optimize()</span><br></pre></td></tr></table></figure>
<h3 id="3-3-粒子群">3-3 粒子群</h3>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> matplotlib <span class="keyword">as</span> mpl</span><br><span class="line">plt.rc(<span class="string">&#x27;font&#x27;</span>,family=<span class="string">&#x27;SimHei&#x27;</span>)</span><br><span class="line">plt.rc(<span class="string">&#x27;axes&#x27;</span>,unicode_minus=<span class="literal">False</span>)</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">fitness_func</span>(<span class="params">X</span>):</span><br><span class="line">    A=<span class="number">10</span>;pi=np.pi</span><br><span class="line">    x=X[:,<span class="number">0</span>];y=X[:,<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">return</span> <span class="number">2</span>*A+x**<span class="number">2</span>-A*np.cos(<span class="number">2</span>*pi*x)+y**<span class="number">2</span>-A*np.cos(<span class="number">2</span>*pi*y)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">velocity_update</span>(<span class="params">V,X,pbest,gbest,c1,c2,w,max_val</span>):</span><br><span class="line">    size=X.shape[<span class="number">0</span>]</span><br><span class="line">    r1=np.random.random((size,<span class="number">1</span>))</span><br><span class="line">    r2=np.random.random((size,<span class="number">1</span>))</span><br><span class="line">    V=w*V+c1*r1*(pbest-X)+c2*r2*(gbest-X)</span><br><span class="line">    V[V&lt;-max_val]=-max_val</span><br><span class="line">    V[V&gt;max_val]=max_val</span><br><span class="line">    <span class="keyword">return</span> V</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">position_update</span>(<span class="params">X,V</span>):</span><br><span class="line">    <span class="keyword">return</span> X+V</span><br><span class="line">w=<span class="number">1</span>;c1=<span class="number">2</span>;c2=<span class="number">2</span>;r1=<span class="literal">None</span>;r2=<span class="literal">None</span>;dim=<span class="number">2</span>;size=<span class="number">20</span>;iter_num=<span class="number">1000</span></span><br><span class="line">max_val=<span class="number">0.5</span>;best_fitness=<span class="built_in">float</span>(<span class="number">9e10</span>)</span><br><span class="line">fitness_value_list=[]</span><br><span class="line">X=np.random.uniform(-<span class="number">5</span>,<span class="number">5</span>,size=(size,dim))</span><br><span class="line">V=np.random.uniform(-<span class="number">0.5</span>,<span class="number">0.5</span>,size=(size,dim))</span><br><span class="line">p_fitness=fitness_func(X)</span><br><span class="line">g=p_fitness.<span class="built_in">min</span>()</span><br><span class="line">fitness_value_list.append(g)</span><br><span class="line">pbest=X</span><br><span class="line">gbest=X[p_fitness.argmin()]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,iter_num):</span><br><span class="line">    V=velocity_update(V,X,pbest,gbest,c1,c2,w,max_val)</span><br><span class="line">    X=position_update(X,V)</span><br><span class="line">    p_fitness2=fitness_func(X)</span><br><span class="line">    g_fitness2=p_fitness2.<span class="built_in">min</span>()</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(size):</span><br><span class="line">        <span class="keyword">if</span> p_fitness[j]&gt;p_fitness2[j]:</span><br><span class="line">            pbest[j]=X[j]</span><br><span class="line">            p_fitness[j]=p_fitness2[j]</span><br><span class="line">    <span class="keyword">if</span> g&gt;g_fitness2:</span><br><span class="line">        gbest=X[p_fitness2.argmin()]</span><br><span class="line">        g=g_fitness2</span><br><span class="line">    fitness_value_list.append(g)</span><br><span class="line"><span class="built_in">print</span>(fitness_value_list[-<span class="number">1</span>])</span><br><span class="line"><span class="built_in">print</span>(gbest)</span><br><span class="line">plt.plot(fitness_value_list,color=<span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;迭代过程&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h3 id="3-3-遗传算法">3-3 遗传算法</h3>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> numpy.random <span class="keyword">import</span> randint, rand, shuffle</span><br><span class="line"><span class="keyword">from</span> matplotlib.pyplot <span class="keyword">import</span> plot, show, rc</span><br><span class="line">a=np.loadtxt(<span class="string">&quot;各个城市的最短路径.txt&quot;</span>)</span><br><span class="line">d=a;N=<span class="built_in">len</span>(d)</span><br><span class="line">w=<span class="number">50</span>; g=<span class="number">10</span>  <span class="comment">#w为种群的个数，g为进化的代数</span></span><br><span class="line">J=[]; </span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> np.arange(w):</span><br><span class="line">    c=np.arange(<span class="number">1</span>,N-<span class="number">1</span>); shuffle(c)</span><br><span class="line">    c1=np.r_[<span class="number">0</span>,c,<span class="number">101</span>]; flag=<span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> flag&gt;<span class="number">0</span>:</span><br><span class="line">        flag=<span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> np.arange(<span class="number">1</span>,N-<span class="number">3</span>):</span><br><span class="line">            <span class="keyword">for</span> n <span class="keyword">in</span> np.arange(m+<span class="number">1</span>,N-<span class="number">2</span>):</span><br><span class="line">                <span class="keyword">if</span> d[c1[m],c1[n]]+d[c1[m+<span class="number">1</span>],c1[n+<span class="number">1</span>]]&lt;\</span><br><span class="line">                    d[c1[m],c1[m+<span class="number">1</span>]]+d[c1[n],c1[n+<span class="number">1</span>]]:</span><br><span class="line">                    c1[m+<span class="number">1</span>:n+<span class="number">1</span>]=c1[n:m:-<span class="number">1</span>]; flag=<span class="number">1</span></span><br><span class="line">    c1[c1]=np.arange(N); J.append(c1)</span><br><span class="line">J=np.array(J)/(N-<span class="number">1</span>)</span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> np.arange(g):</span><br><span class="line">    A=J.copy()</span><br><span class="line">    c1=np.arange(w); shuffle(c1) </span><br><span class="line">    c2=randint(<span class="number">2</span>,<span class="number">100</span>,w)  <span class="comment">#交叉点的数据</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> np.arange(<span class="number">0</span>,w,<span class="number">2</span>):</span><br><span class="line">        temp=A[c1[i],c2[i]:N-<span class="number">1</span>]  <span class="comment">#保存中间变量</span></span><br><span class="line">        A[c1[i],c2[i]:N-<span class="number">1</span>]=A[c1[i+<span class="number">1</span>],c2[i]:N-<span class="number">1</span>]</span><br><span class="line">        A[c1[i+<span class="number">1</span>],c2[i]:N-<span class="number">1</span>]=temp</span><br><span class="line">    B=A.copy()</span><br><span class="line">    by=[]  <span class="comment">#初始化变异染色体的序号</span></span><br><span class="line">    <span class="keyword">while</span> <span class="built_in">len</span>(by)&lt;<span class="number">1</span>: by=np.where(rand(w)&lt;<span class="number">0.1</span>)</span><br><span class="line">    by=by[<span class="number">0</span>]; B=B[by,:]</span><br><span class="line">    G=np.r_[J,A,B]</span><br><span class="line">    ind=np.argsort(G,axis=<span class="number">1</span>)  <span class="comment">#把染色体翻译成0,1，…，101</span></span><br><span class="line">    NN=G.shape[<span class="number">0</span>]; L=np.zeros(NN)</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> np.arange(NN):</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> np.arange(<span class="number">101</span>):</span><br><span class="line">            L[j]=L[j]+d[ind[j,i],ind[j,i+<span class="number">1</span>]]</span><br><span class="line">    ind2=np.argsort(L)</span><br><span class="line">    J=G[ind2,:]</span><br><span class="line">path=ind[ind2[<span class="number">0</span>],:]; zL=L[ind2[<span class="number">0</span>]]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;所求的巡航路径长度为：&quot;</span>,zL)</span><br></pre></td></tr></table></figure>
<h3 id="3-4-图论与路径">3-4 图论与路径</h3>
<p>最大流</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx</span><br><span class="line"><span class="keyword">import</span> pylab <span class="keyword">as</span> plt</span><br><span class="line">L=[(<span class="number">1</span>,<span class="number">2</span>,<span class="number">5</span>),(<span class="number">1</span>,<span class="number">3</span>,<span class="number">3</span>),(<span class="number">2</span>,<span class="number">4</span>,<span class="number">2</span>),(<span class="number">3</span>,<span class="number">2</span>,<span class="number">1</span>),(<span class="number">3</span>,<span class="number">5</span>,<span class="number">4</span>),(<span class="number">4</span>,<span class="number">3</span>,<span class="number">1</span>),(<span class="number">4</span>,<span class="number">5</span>,<span class="number">3</span>),(<span class="number">4</span>,<span class="number">6</span>,<span class="number">2</span>),(<span class="number">5</span>,<span class="number">6</span>,<span class="number">5</span>)]</span><br><span class="line">G=nx.DiGraph()</span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(L)):</span><br><span class="line">    G.add_edge(L[k][<span class="number">0</span>]-<span class="number">1</span>,L[k][<span class="number">1</span>]-<span class="number">1</span>, capacity=L[k][<span class="number">2</span>])</span><br><span class="line">value, flow_dict= nx.maximum_flow(G, <span class="number">0</span>, <span class="number">5</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;最大流的流量为：&quot;</span>,value)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;最大流为：&quot;</span>, flow_dict)</span><br><span class="line">n = <span class="built_in">len</span>(flow_dict)</span><br><span class="line">adj_mat = np.zeros((n, n), dtype=<span class="built_in">int</span>)</span><br><span class="line"><span class="keyword">for</span> i, adj <span class="keyword">in</span> flow_dict.items():</span><br><span class="line">    <span class="keyword">for</span> j, weight <span class="keyword">in</span> adj.items():</span><br><span class="line">        adj_mat[i,j] = weight</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;最大流的邻接矩阵为：\n&quot;</span>,adj_mat)</span><br><span class="line">ni,nj=np.nonzero(adj_mat)  <span class="comment">#非零弧的两端点编号</span></span><br><span class="line">key=<span class="built_in">range</span>(n)</span><br><span class="line">s=[<span class="string">&#x27;v&#x27;</span>+<span class="built_in">str</span>(i+<span class="number">1</span>) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line">s=<span class="built_in">dict</span>(<span class="built_in">zip</span>(key,s)) <span class="comment">#构造用于顶点标注的字符字典</span></span><br><span class="line">plt.rc(<span class="string">&#x27;font&#x27;</span>,size=<span class="number">16</span>)</span><br><span class="line">pos=nx.shell_layout(G)  <span class="comment">#设置布局</span></span><br><span class="line">w=nx.get_edge_attributes(G,<span class="string">&#x27;capacity&#x27;</span>)</span><br><span class="line">nx.draw(G,pos,font_weight=<span class="string">&#x27;bold&#x27;</span>,labels=s,node_color=<span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">nx.draw_networkx_edge_labels(G,pos,edge_labels=w)</span><br><span class="line">path_edges=<span class="built_in">list</span>(<span class="built_in">zip</span>(ni,nj))</span><br><span class="line">nx.draw_networkx_edges(G,pos,edgelist=path_edges,</span><br><span class="line">            edge_color=<span class="string">&#x27;r&#x27;</span>,width=<span class="number">3</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>最小流</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx</span><br><span class="line">L=[(<span class="number">1</span>,<span class="number">2</span>,<span class="number">5</span>,<span class="number">3</span>),(<span class="number">1</span>,<span class="number">3</span>,<span class="number">3</span>,<span class="number">6</span>),(<span class="number">2</span>,<span class="number">4</span>,<span class="number">2</span>,<span class="number">8</span>),(<span class="number">3</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">2</span>),(<span class="number">3</span>,<span class="number">5</span>,<span class="number">4</span>,<span class="number">2</span>),</span><br><span class="line">   (<span class="number">4</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>),(<span class="number">4</span>,<span class="number">5</span>,<span class="number">3</span>,<span class="number">4</span>),(<span class="number">4</span>,<span class="number">6</span>,<span class="number">2</span>,<span class="number">10</span>),(<span class="number">5</span>,<span class="number">6</span>,<span class="number">5</span>,<span class="number">2</span>)]</span><br><span class="line">G=nx.DiGraph()</span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(L)):</span><br><span class="line">    G.add_edge(L[k][<span class="number">0</span>]-<span class="number">1</span>,L[k][<span class="number">1</span>]-<span class="number">1</span>, capacity=L[k][<span class="number">2</span>], weight=L[k][<span class="number">3</span>])</span><br><span class="line">mincostFlow=nx.max_flow_min_cost(G,<span class="number">0</span>,<span class="number">5</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;所求流为：&quot;</span>,mincostFlow)</span><br><span class="line">mincost=nx.cost_of_flow(G, mincostFlow)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;最小费用为：&quot;</span>, mincost)</span><br><span class="line">flow_mat=np.zeros((<span class="number">6</span>,<span class="number">6</span>),dtype=<span class="built_in">int</span>)</span><br><span class="line"><span class="keyword">for</span> i,adj <span class="keyword">in</span> mincostFlow.items():</span><br><span class="line">    <span class="keyword">for</span> j,f <span class="keyword">in</span> adj.items():</span><br><span class="line">        flow_mat[i,j]=f</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;最小费用最大流的邻接矩阵为：\n&quot;</span>,flow_mat)</span><br></pre></td></tr></table></figure>
<p>最小生成树</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx</span><br><span class="line"><span class="keyword">import</span> pylab <span class="keyword">as</span> plt</span><br><span class="line">L=[(<span class="number">1</span>,<span class="number">2</span>,<span class="number">8</span>),(<span class="number">1</span>,<span class="number">3</span>,<span class="number">4</span>),(<span class="number">1</span>,<span class="number">5</span>,<span class="number">2</span>),(<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>),(<span class="number">3</span>,<span class="number">4</span>,<span class="number">2</span>),(<span class="number">3</span>,<span class="number">5</span>,<span class="number">1</span>),(<span class="number">4</span>,<span class="number">5</span>,<span class="number">5</span>)]</span><br><span class="line">b=nx.Graph()</span><br><span class="line">b.add_nodes_from(<span class="built_in">range</span>(<span class="number">1</span>,<span class="number">6</span>))</span><br><span class="line">b.add_weighted_edges_from(L)</span><br><span class="line">T=nx.minimum_spanning_tree(b)  <span class="comment">#返回可迭代对象</span></span><br><span class="line">w=nx.get_edge_attributes(T,<span class="string">&#x27;weight&#x27;</span>) <span class="comment">#提取字典数据</span></span><br><span class="line">TL=<span class="built_in">sum</span>(w.values())  <span class="comment">#计算最小生成树的长度</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;最小生成树为:&quot;</span>,w)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;最小生成树的长度为：&quot;</span>,TL)</span><br><span class="line">pos=nx.shell_layout(b)</span><br><span class="line">nx.draw(T,pos,node_size=<span class="number">280</span>,with_labels=<span class="literal">True</span>,node_color=<span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">nx.draw_networkx_edge_labels(T,pos,edge_labels=w)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>最短路径</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> inf</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">folyd</span>(<span class="params">mat</span>):</span><br><span class="line">    n=<span class="built_in">len</span>(mat)</span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">                <span class="keyword">if</span> mat[i][k]+mat[k][j]&lt;mat[i][j]:</span><br><span class="line">                    mat[i][j]=mat[i][k]+mat[k][j]</span><br><span class="line">    <span class="keyword">return</span> mat</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">dijkstra</span>(<span class="params">mat,start</span>):</span><br><span class="line">    n=<span class="built_in">len</span>(mat)</span><br><span class="line">    dis=[];temp=[];</span><br><span class="line">    dis.extend(mat[start]);temp.extend(mat[start])</span><br><span class="line">    temp[start]=inf</span><br><span class="line">    parents=[start]*n;visited=[start];</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n-<span class="number">1</span>):</span><br><span class="line">        i=temp.index(<span class="built_in">min</span>(temp))</span><br><span class="line">        temp[i]=inf</span><br><span class="line">        visited.append(i)</span><br><span class="line">        <span class="built_in">print</span>(visited)</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">            <span class="keyword">if</span> j <span class="keyword">not</span> <span class="keyword">in</span> visited:</span><br><span class="line">                <span class="keyword">if</span> mat[i][j]+dis[i]&lt;dis[j]:</span><br><span class="line">                    temp[j]=dis[j]=mat[i][j]+dis[i]</span><br><span class="line">                    parents[j]=i</span><br><span class="line">        path=[i]</span><br><span class="line">        k=i</span><br><span class="line">        <span class="keyword">while</span> k !=start:</span><br><span class="line">            path.append(parents[k])</span><br><span class="line">            k=parents[k]</span><br><span class="line">        path.reverse()</span><br><span class="line">        <span class="built_in">print</span>(<span class="built_in">str</span>(path))</span><br><span class="line">        <span class="built_in">print</span>(<span class="built_in">str</span>(i),<span class="string">&#x27;:&#x27;</span>,<span class="string">&#x27;-&gt;&#x27;</span>.join(<span class="built_in">str</span>(path).split()))</span><br><span class="line">    <span class="built_in">print</span>(dis)</span><br><span class="line">a=np.loadtxt(<span class="string">&#x27;ali535.txt&#x27;</span>)</span><br><span class="line">time0=time.time()</span><br><span class="line">mat=folyd(a)</span><br><span class="line">time1=time.time()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;已完成:&#x27;</span>,time1-time0)</span><br><span class="line">time0=time.time()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(mat.shape[<span class="number">0</span>]):</span><br><span class="line">    dijkstra(a,i)</span><br><span class="line">time1=time.time()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;已完成:&#x27;</span>,time1-time0)</span><br><span class="line">pd.DataFrame(mat).to_excel(<span class="string">&#x27;最短路径.xlsx&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="3-5-回归模型">3-5 回归模型</h3>
<p>一元线性回归</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">% 清除环境变量</span></span><br><span class="line">clear; clc; close all;</span><br><span class="line"></span><br><span class="line">x=[<span class="number">143</span> <span class="number">145</span> <span class="number">146</span> <span class="number">147</span> <span class="number">149</span> <span class="number">150</span> <span class="number">153</span> <span class="number">154</span> <span class="number">155</span> <span class="number">156</span> <span class="number">157</span> <span class="number">158</span> <span class="number">159</span> <span class="number">160</span> <span class="number">162</span> <span class="number">164</span>]&#x27;;</span><br><span class="line">X=[<span class="built_in">ones</span>(<span class="number">16</span>,<span class="number">1</span>) x] ;</span><br><span class="line">y=[<span class="number">88</span> <span class="number">85</span> <span class="number">88</span> <span class="number">91</span> <span class="number">92</span> <span class="number">93</span> <span class="number">93</span> <span class="number">95</span> <span class="number">96</span> <span class="number">98</span> <span class="number">97</span> <span class="number">96</span> <span class="number">98</span> <span class="number">99</span> <span class="number">100</span> <span class="number">102</span>]&#x27;;</span><br><span class="line">n=<span class="number">16</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">% 绘制散点图</span></span><br><span class="line"><span class="built_in">figure</span>;</span><br><span class="line"><span class="built_in">scatter</span>(x, y, <span class="string">&#x27;filled&#x27;</span>);</span><br><span class="line">title(<span class="string">&#x27;散点图&#x27;</span>);</span><br><span class="line">xlabel(<span class="string">&#x27;X值&#x27;</span>);</span><br><span class="line">ylabel(<span class="string">&#x27;Y值&#x27;</span>);</span><br><span class="line">grid on;</span><br><span class="line"></span><br><span class="line"><span class="comment">% 线性回归拟合</span></span><br><span class="line">[b, bint, r, rint, stats] = regress(y, [X]);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">% 计算R平方和调整R平方</span></span><br><span class="line">y_pred = b(<span class="number">1</span>) + b(<span class="number">2</span>) * x;</span><br><span class="line">SS_res = sum((y - y_pred).^<span class="number">2</span>);</span><br><span class="line">SS_tot = sum((y - <span class="built_in">mean</span>(y)).^<span class="number">2</span>);</span><br><span class="line">R2 = <span class="number">1</span> - SS_res / SS_tot;</span><br><span class="line"></span><br><span class="line">b</span><br><span class="line">stats</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">% 打印结果</span></span><br><span class="line">fprintf(<span class="string">&#x27;截距(beta_0): %f\n&#x27;</span>, b(<span class="number">1</span>));</span><br><span class="line">fprintf(<span class="string">&#x27;斜率(beta_1): %f\n&#x27;</span>, b(<span class="number">2</span>));</span><br><span class="line">fprintf(<span class="string">&#x27;R平方: %f\n&#x27;</span>, R2);</span><br><span class="line"><span class="comment">% fprintf(&#x27;调整R平方: %f\n&#x27;, R2_adj);</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% 绘制拟合曲线</span></span><br><span class="line"><span class="built_in">hold</span> on;</span><br><span class="line">x_fit = <span class="built_in">linspace</span>(<span class="built_in">min</span>(x), <span class="built_in">max</span>(x), <span class="number">100</span>);</span><br><span class="line">y_fit = b(<span class="number">1</span>) + b(<span class="number">2</span>) * x_fit;</span><br><span class="line"><span class="built_in">plot</span>(x_fit, y_fit, <span class="string">&#x27;r-&#x27;</span>, <span class="string">&#x27;LineWidth&#x27;</span>, <span class="number">2</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">%%</span></span><br><span class="line"><span class="built_in">hold</span> on;</span><br><span class="line">rcoplot(r,rint)</span><br><span class="line"><span class="built_in">hold</span> off;</span><br><span class="line"></span><br><span class="line"><span class="comment">%%</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% 残差分析</span></span><br><span class="line">residuals = y - y_pred;</span><br><span class="line"><span class="built_in">figure</span>;</span><br><span class="line">subplot(<span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>);</span><br><span class="line"><span class="built_in">plot</span>(residuals);</span><br><span class="line">title(<span class="string">&#x27;残差图&#x27;</span>);</span><br><span class="line">xlabel(<span class="string">&#x27;观测序号&#x27;</span>);</span><br><span class="line">ylabel(<span class="string">&#x27;残差&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">% 残差的直方图</span></span><br><span class="line">subplot(<span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>);</span><br><span class="line">histogram(residuals, <span class="number">20</span>);</span><br><span class="line">title(<span class="string">&#x27;残差直方图&#x27;</span>);</span><br><span class="line">xlabel(<span class="string">&#x27;残差&#x27;</span>);</span><br><span class="line">ylabel(<span class="string">&#x27;频率&#x27;</span>);</span><br></pre></td></tr></table></figure>
<p>多元线性回归</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">clc;</span><br><span class="line">clear;</span><br><span class="line">x1=[<span class="number">3.5</span> <span class="number">5.3</span> <span class="number">5.1</span> <span class="number">5.8</span> <span class="number">4.2</span> <span class="number">6.0</span> <span class="number">6.8</span> <span class="number">5.5</span> <span class="number">3.1</span> <span class="number">7.2</span> <span class="number">4.5</span> <span class="number">4.9</span> <span class="number">8.0</span> <span class="number">6.5</span> <span class="number">6.5</span> <span class="number">3.7</span> <span class="number">6.2</span> <span class="number">7.0</span> <span class="number">4.0</span> <span class="number">4.5</span> <span class="number">5.9</span> <span class="number">5.6</span> <span class="number">4.8</span> <span class="number">3.9</span>];</span><br><span class="line">x2=[<span class="number">9</span> <span class="number">20</span> <span class="number">18</span> <span class="number">33</span> <span class="number">31</span> <span class="number">13</span> <span class="number">25</span> <span class="number">30</span> <span class="number">5</span> <span class="number">47</span> <span class="number">25</span> <span class="number">11</span> <span class="number">23</span> <span class="number">35</span> <span class="number">39</span> <span class="number">21</span> <span class="number">7</span> <span class="number">40</span> <span class="number">35</span> <span class="number">23</span> <span class="number">33</span> <span class="number">27</span> <span class="number">34</span> <span class="number">15</span>];</span><br><span class="line">x3=[<span class="number">6.1</span> <span class="number">6.4</span> <span class="number">7.4</span> <span class="number">6.7</span> <span class="number">7.5</span> <span class="number">5.9</span> <span class="number">6.0</span> <span class="number">4.0</span> <span class="number">5.8</span> <span class="number">8.3</span> <span class="number">5.0</span> <span class="number">6.4</span> <span class="number">7.6</span> <span class="number">7.0</span> <span class="number">5.0</span> <span class="number">4.0</span> <span class="number">5.5</span> <span class="number">7.0</span> <span class="number">6.0</span> <span class="number">3.5</span> <span class="number">4.9</span> <span class="number">4.3</span> <span class="number">8.0</span> <span class="number">5.0</span>];</span><br><span class="line">Y=[<span class="number">33.2</span> <span class="number">40.3</span> <span class="number">38.7</span> <span class="number">46.8</span> <span class="number">41.4</span> <span class="number">37.5</span> <span class="number">39.0</span> <span class="number">40.7</span> <span class="number">30.1</span> <span class="number">52.9</span> <span class="number">38.2</span> <span class="number">31.8</span> <span class="number">43.3</span> <span class="number">44.1</span> <span class="number">42.5</span> <span class="number">33.6</span> <span class="number">34.2</span> <span class="number">48.0</span> <span class="number">38.0</span> <span class="number">35.9</span> <span class="number">40.4</span> <span class="number">36.8</span> <span class="number">45.2</span> <span class="number">35.1</span>];</span><br><span class="line">n=<span class="number">24</span>; m=<span class="number">3</span>;</span><br><span class="line">X=[<span class="built_in">ones</span>(n,<span class="number">1</span>),x1&#x27;,x2&#x27;,x3&#x27;];</span><br><span class="line">[b,bint,r,rint,stats]=regress(Y&#x27;,X,<span class="number">0.05</span>);</span><br><span class="line"><span class="comment">% b,bint,r,rint,stats</span></span><br><span class="line">b, stats</span><br><span class="line"></span><br><span class="line"><span class="built_in">figure</span>;</span><br><span class="line">subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">1</span>),</span><br><span class="line"><span class="built_in">plot</span>(x1,Y,<span class="string">&#x27;r*&#x27;</span>),</span><br><span class="line">title(<span class="string">&#x27;x1与y的散点图情况&#x27;</span>); <span class="comment">% 添加标题</span></span><br><span class="line">grid on</span><br><span class="line">subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">2</span>),</span><br><span class="line"><span class="built_in">plot</span>(x2,Y,<span class="string">&#x27;g+&#x27;</span>),</span><br><span class="line">title(<span class="string">&#x27;x2与y的散点图情况&#x27;</span>); <span class="comment">% 添加标题</span></span><br><span class="line">grid on</span><br><span class="line">subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">3</span>),</span><br><span class="line"><span class="built_in">plot</span>(x3,Y,<span class="string">&#x27;bp&#x27;</span>),</span><br><span class="line">title(<span class="string">&#x27;x3与y的散点图情况&#x27;</span>); <span class="comment">% 添加标题</span></span><br><span class="line">grid on</span><br><span class="line"></span><br><span class="line"><span class="built_in">figure</span>;</span><br><span class="line">rcoplot(r,rint)</span><br></pre></td></tr></table></figure>
<p>非线性回归</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">clc;</span><br><span class="line">clear;</span><br><span class="line">x1 = [<span class="number">1000</span> <span class="number">600</span> <span class="number">1200</span> <span class="number">500</span> <span class="number">300</span> <span class="number">400</span> <span class="number">1300</span> <span class="number">1100</span> <span class="number">1300</span> <span class="number">300</span>] ;</span><br><span class="line">x2 = [<span class="number">5</span> <span class="number">7</span> <span class="number">6</span> <span class="number">6</span> <span class="number">8</span> <span class="number">7</span> <span class="number">5</span> <span class="number">4</span> <span class="number">3</span> <span class="number">9</span> ]; </span><br><span class="line">y = [<span class="number">100</span> <span class="number">75</span> <span class="number">80</span> <span class="number">70</span> <span class="number">50</span> <span class="number">65</span> <span class="number">90</span> <span class="number">100</span> <span class="number">110</span> <span class="number">60</span> ]&#x27;;</span><br><span class="line">x=[x1&#x27;,x2&#x27;];</span><br><span class="line">rstool(x , y, <span class="string">&#x27;purequadratic&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">%%</span></span><br><span class="line">clc;</span><br><span class="line">clear;</span><br><span class="line">x1 = [<span class="number">1000</span> <span class="number">600</span> <span class="number">1200</span> <span class="number">500</span> <span class="number">300</span> <span class="number">400</span> <span class="number">1300</span> <span class="number">1100</span> <span class="number">1300</span> <span class="number">300</span>] ;</span><br><span class="line">x2 = [<span class="number">5</span> <span class="number">7</span> <span class="number">6</span> <span class="number">6</span> <span class="number">8</span> <span class="number">7</span> <span class="number">5</span> <span class="number">4</span> <span class="number">3</span> <span class="number">9</span> ]; </span><br><span class="line">y = [<span class="number">100</span> <span class="number">75</span> <span class="number">80</span> <span class="number">70</span> <span class="number">50</span> <span class="number">65</span> <span class="number">90</span> <span class="number">100</span> <span class="number">110</span> <span class="number">60</span> ]&#x27;;</span><br><span class="line">X = [<span class="built_in">ones</span>(<span class="number">10</span>,<span class="number">1</span>) x1&#x27; x2&#x27; (x1.^<span class="number">2</span>)&#x27; (x2.^<span class="number">2</span>)&#x27;];</span><br><span class="line">[b,bint,r,rint,stats]=regress(y,X,<span class="number">0.05</span>);</span><br></pre></td></tr></table></figure>
<h3 id="3-6-有监督分类模型">3-6 有监督分类模型</h3>
<p>KNN算法</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> operator</span><br><span class="line"> </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">createDataSet</span>():</span><br><span class="line">    group = array([[<span class="number">1.0</span>, <span class="number">1.1</span>], [<span class="number">1.0</span>, <span class="number">1.0</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0.1</span>]])</span><br><span class="line">    labels = [<span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;B&#x27;</span>, <span class="string">&#x27;B&#x27;</span>]</span><br><span class="line">    <span class="keyword">return</span> group, labels</span><br><span class="line"> </span><br><span class="line">group, labels = createDataSet()</span><br><span class="line"><span class="built_in">print</span>(group)</span><br><span class="line"><span class="built_in">print</span>(labels)</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"> </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">createDataSet</span>():</span><br><span class="line">    group = np.array([[<span class="number">1.0</span>, <span class="number">1.1</span>], [<span class="number">1.0</span>, <span class="number">1.0</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0.1</span>]])</span><br><span class="line">    labels = [<span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;B&#x27;</span>, <span class="string">&#x27;B&#x27;</span>]</span><br><span class="line">    <span class="keyword">return</span> group, labels</span><br><span class="line"> </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plotDataSet</span>(<span class="params">group, labels</span>):</span><br><span class="line">    label_dict = &#123;<span class="string">&#x27;A&#x27;</span>: <span class="string">&#x27;red&#x27;</span>, <span class="string">&#x27;B&#x27;</span>: <span class="string">&#x27;blue&#x27;</span>&#125;</span><br><span class="line">    colors = [label_dict[label] <span class="keyword">for</span> label <span class="keyword">in</span> labels]</span><br><span class="line">    fig, ax = plt.subplots()</span><br><span class="line">    ax.scatter(group[:, <span class="number">0</span>], group[:, <span class="number">1</span>], c=colors)</span><br><span class="line">    ax.set_xlabel(<span class="string">&#x27;x&#x27;</span>)</span><br><span class="line">    ax.set_ylabel(<span class="string">&#x27;y&#x27;</span>)</span><br><span class="line">    ax.set_title(<span class="string">&#x27;Data Set&#x27;</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"> </span><br><span class="line">group, labels = createDataSet()</span><br><span class="line">plotDataSet(group, labels)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">classify0</span>(<span class="params">inX, dataSet, labels, k</span>):</span><br><span class="line">    <span class="comment">#numpy函数shape[0]返回dataSet的行数</span></span><br><span class="line">    dataSetSize = dataSet.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="comment">#在列向量方向上重复inX共1次(横向),行向量方向上重复inX共dataSetSize次(纵向)</span></span><br><span class="line">    diffMat = np.tile(inX, (dataSetSize, <span class="number">1</span>)) - dataSet</span><br><span class="line">    <span class="comment">#二维特征相减后平方</span></span><br><span class="line">    sqDiffMat = diffMat**<span class="number">2</span></span><br><span class="line">    <span class="comment">#sum()所有元素相加,sum(0)列相加,sum(1)行相加</span></span><br><span class="line">    sqDistances = sqDiffMat.<span class="built_in">sum</span>(axis=<span class="number">1</span>)</span><br><span class="line">    <span class="comment">#开方,计算出距离</span></span><br><span class="line">    distances = sqDistances**<span class="number">0.5</span></span><br><span class="line">    <span class="comment">#返回distances中元素从小到大排序后的索引值</span></span><br><span class="line">    sortedDistIndices = distances.argsort()</span><br><span class="line">    <span class="comment">#定一个记录类别次数的字典</span></span><br><span class="line">    classCount = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(k):</span><br><span class="line">        <span class="comment">#取出前k个元素的类别</span></span><br><span class="line">        voteIlabel = labels[sortedDistIndices[i]]</span><br><span class="line">        <span class="comment">#dict.get(key,default=None),字典的get()方法,返回指定键的值,如果值不在字典中返回默认值。</span></span><br><span class="line">        <span class="comment">#计算类别次数</span></span><br><span class="line">        classCount[voteIlabel] = classCount.get(voteIlabel,<span class="number">0</span>) + <span class="number">1</span></span><br><span class="line">    <span class="comment">#python3中用items()替换python2中的iteritems()</span></span><br><span class="line">    <span class="comment">#key=operator.itemgetter(1)根据字典的值进行排序</span></span><br><span class="line">    <span class="comment">#key=operator.itemgetter(0)根据字典的键进行排序</span></span><br><span class="line">    <span class="comment">#reverse降序排序字典</span></span><br><span class="line">    sortedClassCount = <span class="built_in">sorted</span>(classCount.items(),key=operator.itemgetter(<span class="number">1</span>),reverse=<span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># import pdb</span></span><br><span class="line">    <span class="comment"># pdb.set_trace()</span></span><br><span class="line">    <span class="comment">#返回次数最多的类别,即所要分类的类别</span></span><br><span class="line">    <span class="keyword">return</span> sortedClassCount[<span class="number">0</span>][<span class="number">0</span>]</span><br></pre></td></tr></table></figure>
<p>SVM算法、朴素贝叶斯算法</p>
<p><em>参考代码文件夹内容</em></p>
<h3 id="3-7-无监督分类算法">3-7 无监督分类算法</h3>
<p>DBSCAN</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> DBSCAN</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_blobs</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置matplotlib支持中文显示</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]  <span class="comment"># 用黑体显示中文</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span>  <span class="comment"># 正常显示负号</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成样本数据</span></span><br><span class="line">centers = [[<span class="number">1</span>, <span class="number">1</span>], [-<span class="number">1</span>, -<span class="number">1</span>], [<span class="number">1</span>, -<span class="number">1</span>]]</span><br><span class="line">X, labels_true = make_blobs(n_samples=<span class="number">750</span>, centers=centers, cluster_std=<span class="number">0.4</span>,</span><br><span class="line">                            random_state=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">X = StandardScaler().fit_transform(X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算k-距离图</span></span><br><span class="line">min_samples = <span class="number">10</span></span><br><span class="line">k_distances = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(X)):</span><br><span class="line">    distances = np.linalg.norm(X - X[i], axis=<span class="number">1</span>)</span><br><span class="line">    distances = np.sort(distances)</span><br><span class="line">    k_distance = distances[min_samples - <span class="number">1</span>]  <span class="comment"># 第min_samples个最近邻的距离</span></span><br><span class="line">    k_distances.append(k_distance)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 排序k-距离</span></span><br><span class="line">sorted_k_distances = <span class="built_in">sorted</span>(k_distances)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用选定的eps值计算DBSCAN</span></span><br><span class="line">eps = <span class="number">0.3</span>  <span class="comment"># 从k-距离图中选择的eps值</span></span><br><span class="line">db = DBSCAN(eps=eps, min_samples=min_samples).fit(X)</span><br><span class="line">core_samples_mask = np.zeros_like(db.labels_, dtype=<span class="built_in">bool</span>)</span><br><span class="line">core_samples_mask[db.core_sample_indices_] = <span class="literal">True</span></span><br><span class="line">labels = db.labels_</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算标签中的聚类数量，忽略噪声点</span></span><br><span class="line">n_clusters_ = <span class="built_in">len</span>(<span class="built_in">set</span>(labels)) - (<span class="number">1</span> <span class="keyword">if</span> -<span class="number">1</span> <span class="keyword">in</span> labels <span class="keyword">else</span> <span class="number">0</span>)</span><br><span class="line">n_noise_ = <span class="built_in">list</span>(labels).count(-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;估计的聚类数量: %d&#x27;</span> % n_clusters_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;估计的噪声点数量: %d&#x27;</span> % n_noise_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;同质性: %0.3f&quot;</span> % metrics.homogeneity_score(labels_true, labels))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;完整性: %0.3f&quot;</span> % metrics.completeness_score(labels_true, labels))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;V-测量: %0.3f&quot;</span> % metrics.v_measure_score(labels_true, labels))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;调整后的Rand指数: %0.3f&quot;</span></span><br><span class="line">      % metrics.adjusted_rand_score(labels_true, labels))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;调整后的互信息: %0.3f&quot;</span></span><br><span class="line">      % metrics.adjusted_mutual_info_score(labels_true, labels))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;轮廓系数: %0.3f&quot;</span></span><br><span class="line">      % metrics.silhouette_score(X, labels))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建画布</span></span><br><span class="line">fig, (ax1, ax2) = plt.subplots(<span class="number">1</span>, <span class="number">2</span>, figsize=(<span class="number">12</span>, <span class="number">6</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制k-距离图</span></span><br><span class="line">ax1.plot(<span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(sorted_k_distances) + <span class="number">1</span>), sorted_k_distances, marker=<span class="string">&#x27;o&#x27;</span>)</span><br><span class="line">ax1.set_xlabel(<span class="string">&#x27;数据点索引&#x27;</span>)</span><br><span class="line">ax1.set_ylabel(<span class="string">&#x27;k-距离&#x27;</span>)</span><br><span class="line">ax1.set_title(<span class="string">&#x27;K-距离图&#x27;</span>)</span><br><span class="line">ax1.grid(<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制聚类结果</span></span><br><span class="line"><span class="comment"># 黑色用于表示噪声点</span></span><br><span class="line">unique_labels = <span class="built_in">set</span>(labels)</span><br><span class="line">colors = [<span class="string">&#x27;#FF0000&#x27;</span>, <span class="string">&#x27;#00FF00&#x27;</span>, <span class="string">&#x27;#0000FF&#x27;</span>, <span class="string">&#x27;#FFFF00&#x27;</span>, <span class="string">&#x27;#00FFFF&#x27;</span>, <span class="string">&#x27;#FF00FF&#x27;</span>, <span class="string">&#x27;#800080&#x27;</span>]  <span class="comment"># 自定义颜色列表</span></span><br><span class="line">colors = colors[:<span class="built_in">len</span>(unique_labels)]  <span class="comment"># 确保颜色列表长度与聚类数量一致</span></span><br><span class="line"><span class="keyword">for</span> k, col <span class="keyword">in</span> <span class="built_in">zip</span>(unique_labels, colors):</span><br><span class="line">    <span class="keyword">if</span> k == -<span class="number">1</span>:</span><br><span class="line">        <span class="comment"># 黑色用于噪声点</span></span><br><span class="line">        col = <span class="string">&#x27;black&#x27;</span></span><br><span class="line"></span><br><span class="line">    class_member_mask = (labels == k)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 核心样本</span></span><br><span class="line">    xy = X[class_member_mask &amp; core_samples_mask]</span><br><span class="line">    ax2.scatter(xy[:, <span class="number">0</span>], xy[:, <span class="number">1</span>], c=col, edgecolors=<span class="string">&#x27;k&#x27;</span>, s=<span class="number">100</span>, marker=<span class="string">&#x27;s&#x27;</span>)  <span class="comment"># 使用正方形标记</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 非核心样本</span></span><br><span class="line">    xy = X[class_member_mask &amp; ~core_samples_mask]</span><br><span class="line">    ax2.scatter(xy[:, <span class="number">0</span>], xy[:, <span class="number">1</span>], c=col, edgecolors=<span class="string">&#x27;k&#x27;</span>, s=<span class="number">60</span>, marker=<span class="string">&#x27;o&#x27;</span>)  <span class="comment"># 使用圆形标记</span></span><br><span class="line"></span><br><span class="line">ax2.set_title(<span class="string">&#x27;估计的聚类数量: %d&#x27;</span> % n_clusters_)</span><br><span class="line">plt.tight_layout()  <span class="comment"># 调整子图间距</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>K-means</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># #!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># # -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># # @Time    : 2024/8/9 15:21</span></span><br><span class="line"><span class="comment"># # @Author  : iszhou</span></span><br><span class="line"><span class="comment"># # @Email   :</span></span><br><span class="line"><span class="comment"># # @File    : demo.py</span></span><br><span class="line"><span class="comment"># # @purpose :</span></span><br><span class="line"><span class="comment"># # @software: PyCharm</span></span><br><span class="line"><span class="comment"># # @install packages: pip install -i https://pypi.tuna.tsinghua.edu.cn/simple bag_name</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_blobs</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> silhouette_score</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成模拟数据</span></span><br><span class="line">X, y_true = make_blobs(n_samples=<span class="number">300</span>, centers=<span class="number">5</span>, cluster_std=<span class="number">0.50</span>, random_state=<span class="number">12345</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据标准化</span></span><br><span class="line">scaler = StandardScaler()</span><br><span class="line">X = scaler.fit_transform(X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 肘部法则确定K值</span></span><br><span class="line">distortions = []</span><br><span class="line">silhouette_scores = []  <span class="comment"># 添加轮廓系数列表</span></span><br><span class="line">K = <span class="built_in">range</span>(<span class="number">2</span>, <span class="number">10</span>)  <span class="comment"># K 的范围从 2 开始，因为 K=1 没有意义</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> K:</span><br><span class="line">    kmeanModel = KMeans(n_clusters=k).fit(X)</span><br><span class="line">    distortions.append(kmeanModel.inertia_)</span><br><span class="line">    silhouette_scores.append(silhouette_score(X, kmeanModel.labels_))  <span class="comment"># 计算轮廓系数</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个大的图形窗口</span></span><br><span class="line">fig, axs = plt.subplots(<span class="number">1</span>, <span class="number">3</span>, figsize=(<span class="number">18</span>, <span class="number">6</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制肘部图</span></span><br><span class="line">axs[<span class="number">0</span>].plot(K, distortions, <span class="string">&#x27;bx-&#x27;</span>)</span><br><span class="line">axs[<span class="number">0</span>].set_xlabel(<span class="string">&#x27;k&#x27;</span>)</span><br><span class="line">axs[<span class="number">0</span>].set_ylabel(<span class="string">&#x27;Distortion&#x27;</span>)</span><br><span class="line">axs[<span class="number">0</span>].set_title(<span class="string">&#x27;The Elbow Method showing the optimal k&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制轮廓系数图</span></span><br><span class="line">axs[<span class="number">1</span>].plot(K, silhouette_scores, <span class="string">&#x27;gx-&#x27;</span>)</span><br><span class="line">axs[<span class="number">1</span>].set_xlabel(<span class="string">&#x27;k&#x27;</span>)</span><br><span class="line">axs[<span class="number">1</span>].set_ylabel(<span class="string">&#x27;Silhouette Score&#x27;</span>)</span><br><span class="line">axs[<span class="number">1</span>].set_title(<span class="string">&#x27;Silhouette Scores for Different k Values&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 自动选择最佳K值</span></span><br><span class="line">optimal_k = silhouette_scores.index(<span class="built_in">max</span>(silhouette_scores)) + <span class="number">2</span>  <span class="comment"># 找到最大轮廓系数对应的 K 值</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Optimal number of clusters: <span class="subst">&#123;optimal_k&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用确定的K值进行聚类</span></span><br><span class="line">kmeans = KMeans(n_clusters=optimal_k, random_state=<span class="number">0</span>)</span><br><span class="line">kmeans.fit(X)</span><br><span class="line">labels = kmeans.labels_</span><br><span class="line">centroids = kmeans.cluster_centers_</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可视化聚类结果</span></span><br><span class="line">axs[<span class="number">2</span>].scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=labels, cmap=<span class="string">&#x27;viridis&#x27;</span>)</span><br><span class="line">axs[<span class="number">2</span>].scatter(centroids[:, <span class="number">0</span>], centroids[:, <span class="number">1</span>], c=<span class="string">&#x27;red&#x27;</span>, s=<span class="number">300</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line">axs[<span class="number">2</span>].set_title(<span class="string">&#x27;K-means Clustering with Optimal K&#x27;</span>)</span><br><span class="line">axs[<span class="number">2</span>].set_xlabel(<span class="string">&#x27;Feature 1&#x27;</span>)</span><br><span class="line">axs[<span class="number">2</span>].set_ylabel(<span class="string">&#x27;Feature 2&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示整个图形</span></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>层次聚类</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 综合分类数据集</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> AgglomerativeClustering</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_blobs</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建数据集</span></span><br><span class="line"><span class="comment"># X为样本特征，Y为样本簇类别， 共1000个样本，每个样本2个特征，共4个簇，</span></span><br><span class="line"><span class="comment"># 簇中心在[-1,-1], [0,0],[1,1], [2,2]， 簇方差分别为[0.4, 0.2, 0.2, 0.2]</span></span><br><span class="line">X, y = make_blobs(n_samples=<span class="number">1000</span>, n_features=<span class="number">2</span>,</span><br><span class="line">                  centers=[[-<span class="number">1</span>, -<span class="number">1</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">1</span>], [<span class="number">2</span>, <span class="number">2</span>]],</span><br><span class="line">                  cluster_std=[<span class="number">0.4</span>, <span class="number">0.3</span>, <span class="number">0.2</span>, <span class="number">0.1</span>],</span><br><span class="line">                  random_state=<span class="number">9</span>)</span><br><span class="line"><span class="comment"># 数据可视化</span></span><br><span class="line">plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], marker=<span class="string">&#x27;o&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义颜色列表</span></span><br><span class="line">colors = [<span class="string">&#x27;#FF0000&#x27;</span>, <span class="string">&#x27;#00FF00&#x27;</span>, <span class="string">&#x27;#0000FF&#x27;</span>, <span class="string">&#x27;#FFFF00&#x27;</span>, <span class="string">&#x27;#00FFFF&#x27;</span>, <span class="string">&#x27;#FF00FF&#x27;</span>, <span class="string">&#x27;#800080&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> index, metric <span class="keyword">in</span> <span class="built_in">enumerate</span>([<span class="string">&quot;cosine&quot;</span>, <span class="string">&quot;euclidean&quot;</span>, <span class="string">&quot;cityblock&quot;</span>]):</span><br><span class="line">    model = AgglomerativeClustering(</span><br><span class="line">        n_clusters=<span class="number">4</span>, linkage=<span class="string">&quot;average&quot;</span>, affinity=metric</span><br><span class="line">    )</span><br><span class="line">    model.fit(X)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;%s Silhouette Coefficient: %0.3f&quot;</span></span><br><span class="line">          % (metric, metrics.silhouette_score(X, model.labels_, metric=<span class="string">&#x27;sqeuclidean&#x27;</span>)))</span><br><span class="line"></span><br><span class="line">    plt.figure()</span><br><span class="line">    plt.axes([<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">    <span class="keyword">for</span> l, c <span class="keyword">in</span> <span class="built_in">zip</span>(np.arange(model.n_clusters), colors[:model.n_clusters]):</span><br><span class="line">        row_ix = np.where(l == model.labels_)</span><br><span class="line">        plt.scatter(X[row_ix, <span class="number">0</span>], X[row_ix, <span class="number">1</span>], c=c)</span><br><span class="line">    plt.axis(<span class="string">&quot;tight&quot;</span>)</span><br><span class="line">    plt.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">    plt.suptitle(<span class="string">&quot;AgglomerativeClustering(affinity=%s)&quot;</span> % metric, size=<span class="number">20</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scipy.cluster.hierarchy <span class="keyword">as</span> shc</span><br><span class="line"></span><br><span class="line">plt.figure(figsize =(<span class="number">8</span>, <span class="number">8</span>))</span><br><span class="line">plt.title(<span class="string">&#x27;Visualising the data&#x27;</span>)</span><br><span class="line">Dendrogram = shc.dendrogram((shc.linkage(X, method =<span class="string">&#x27;ward&#x27;</span>)))</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h3 id="时间序列模型">时间序列模型</h3>
<p>ARIMA</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line">clc;clear;</span><br><span class="line"><span class="comment">%% 1. 读取数据 - 请将&#x27;B.xlsx&#x27;替换为您的数据文件名，并将&#x27;data(:,2)&#x27;根据要预测的列确定</span></span><br><span class="line">data = readmatrix(<span class="string">&#x27;sj2.xlsx&#x27;</span>);</span><br><span class="line">time_series_data = data(:,<span class="number">2</span>);</span><br><span class="line"><span class="comment">%data（x,y） x是行数 y是列数</span></span><br><span class="line"><span class="comment">%data（:,y）就是指y列对应的所有行的值组成的一个向量</span></span><br><span class="line"><span class="comment">%data(:,[y1:y2]) 就是指y1到y2列的对应的所有行的值组成的一个矩阵</span></span><br><span class="line"></span><br><span class="line"><span class="comment">%% 2. 划分训练集和测试集 - 这里使用80%的数据作为训练集，可以根据需要调整比例</span></span><br><span class="line">train_size = <span class="built_in">round</span>(<span class="built_in">length</span>(time_series_data) * <span class="number">0.8</span>); </span><br><span class="line"><span class="comment">%round(x)将x的每个元素四舍五入为最近的整数,length(x)就是求向量的长度,size(x)输出行列数</span></span><br><span class="line">train_data = time_series_data(<span class="number">1</span>:train_size);</span><br><span class="line">test_data = time_series_data(train_size+<span class="number">1</span>:<span class="keyword">end</span>);</span><br><span class="line"> </span><br><span class="line"><span class="comment">%% 3. 初始化最小AIC和BIC以及最优参数 - 选择模型参数的范围（p、d、q的最大值）</span></span><br><span class="line">max_p = <span class="number">5</span>;</span><br><span class="line">max_d = <span class="number">2</span>;<span class="comment">%在ARIMA模型中，超参数d最常见的取值是0、1、2这些很小的数字。</span></span><br><span class="line">max_q = <span class="number">5</span>;<span class="comment">%在ARIMA模型当中，p和q的值往往取值不高，一般是[1,5]以内的正整数。</span></span><br><span class="line">min_aic = Inf;</span><br><span class="line">min_bic = Inf;</span><br><span class="line">best_p = <span class="number">0</span>;</span><br><span class="line">best_d = <span class="number">0</span>;</span><br><span class="line">best_q = <span class="number">0</span>;</span><br><span class="line"><span class="comment">%实践中更常用的方法是从最小值p=1、q=1的方式开始进行尝试，不断改变p和q的取值，直到模型通过检验或达到我们需要的精度要求。</span></span><br><span class="line"><span class="comment">%% 4. 循环遍历不同的p, d, q值，尝试拟合ARIMA模型，并计算AIC和BIC</span></span><br><span class="line"><span class="keyword">for</span> p = <span class="number">0</span>:max_p</span><br><span class="line">    <span class="keyword">for</span> d = <span class="number">0</span>:max_d</span><br><span class="line">        <span class="keyword">for</span> q = <span class="number">0</span>:max_q</span><br><span class="line">            <span class="comment">% 创建ARIMA模型</span></span><br><span class="line">            Mdl = arima(p, d, q);<span class="comment">%创建不同p,d,q值下的arima模型，目的是为了找到最佳p,d,q值</span></span><br><span class="line">            <span class="comment">% 拟合模型，并计算AIC和BIC</span></span><br><span class="line">            <span class="keyword">try</span>   <span class="comment">%里面语句报错时停止执行，直接跳到catch</span></span><br><span class="line">                [EstMdl,~,logL] = estimate(Mdl, train_data, <span class="string">&#x27;Display&#x27;</span>, <span class="string">&#x27;off&#x27;</span>);<span class="comment">%用时间序列对象的训练集拟合arima模型</span></span><br><span class="line">                <span class="comment">%[EstMdl，EstParamCov，logL，info] = estimate(model,data)model为指定模型，data为数据样本。返回估计参数，EstParamCov—关联的估计方差-协方差矩阵、logL—优化的对数似然目标函数。</span></span><br><span class="line">                [aic, bic] = aicbic(logL, p + q + <span class="number">1</span>, <span class="built_in">length</span>(train_data));</span><br><span class="line">                <span class="comment">%[aic, bic] = aicbic(logL,k,n)logL是模型的对数似然函数值,k为模型的参数数量,n为观测数据的数量</span></span><br><span class="line">                <span class="comment">%AIC和BIC是模型选择的常用准则，用于评估不同模型的拟合能力和复杂度。</span></span><br><span class="line">                <span class="comment">%AIC和BIC的值越小，表示模型的拟合效果越好且更简洁。</span></span><br><span class="line">            <span class="keyword">catch</span></span><br><span class="line">                <span class="keyword">continue</span>;<span class="comment">%会终止当前循环，进行下一次循环</span></span><br><span class="line">            <span class="keyword">end</span></span><br><span class="line"> </span><br><span class="line">            <span class="comment">% 更新最优参数</span></span><br><span class="line">            <span class="keyword">if</span> bic &lt; min_bic</span><br><span class="line">                <span class="comment">%AIC是一个惩罚项，用于防止过度拟合，它的值越小表示模型越好。</span></span><br><span class="line">                <span class="comment">%BIC也类似，但是在惩罚项的计算中对参数数量的贡献更大，因此BIC更倾向于选择更简单的模型。</span></span><br><span class="line">                min_aic = aic;</span><br><span class="line">                min_bic = bic;</span><br><span class="line">                best_p = p;</span><br><span class="line">                best_d = d;</span><br><span class="line">                best_q = q;</span><br><span class="line">            <span class="keyword">end</span></span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">%% 5. 使用最优参数创建ARIMA模型</span></span><br><span class="line">best_mdl = arima(best_p, best_d, best_q);</span><br><span class="line"></span><br><span class="line"><span class="comment">%% 6. 拟合模型</span></span><br><span class="line">EstMdl = estimate(best_mdl, train_data);</span><br><span class="line"><span class="comment">%返回指定的ARIMA模型EstMdl  </span></span><br><span class="line"><span class="comment">%% 7. 对测试集数据后的值进行预测 - 设定预测步长</span></span><br><span class="line">num_steps =  <span class="number">10</span>; <span class="comment">% 预测测试集之后的10天数据</span></span><br><span class="line">[forecast,forecast_RMSE] = forecast(EstMdl, num_steps, <span class="string">&#x27;Y0&#x27;</span>, train_data);</span><br><span class="line"><span class="comment">%预测未来n个时间步长的值，其中Y0为数据初始化模型 </span></span><br><span class="line"><span class="comment">%forecast预测的未来值向量,forecast_RMSE是包含预测区间的置信区间的矩阵</span></span><br><span class="line"></span><br><span class="line"><span class="comment">%% 7. 输出预测结果</span></span><br><span class="line"><span class="built_in">disp</span>([<span class="string">&#x27;预测结果（&#x27;</span>, num2str(num_steps), <span class="string">&#x27;个步长）:&#x27;</span>]);</span><br><span class="line"><span class="built_in">disp</span>(forecast);</span><br><span class="line"><span class="comment">%% 8. 可视化预测结果</span></span><br><span class="line"><span class="built_in">figure</span>;</span><br><span class="line"><span class="built_in">hold</span> on;</span><br><span class="line"><span class="built_in">plot</span>(data(:,<span class="number">1</span>), data(:,<span class="number">2</span>),<span class="string">&#x27;k&#x27;</span>, <span class="string">&#x27;LineWidth&#x27;</span>, <span class="number">1</span>);<span class="built_in">hold</span> on</span><br><span class="line"><span class="comment">%plot(time_series_data, &#x27;k&#x27;, &#x27;LineWidth&#x27;, 1);hold on</span></span><br><span class="line"><span class="comment">%plot(train_size+1:train_size+length(test_data), test_data, &#x27;b&#x27;, &#x27;LineWidth&#x27;, 1); hold on% 绘制测试集数据</span></span><br><span class="line"><span class="built_in">plot</span>(data(train_size+<span class="number">1</span>,<span class="number">1</span>):data(train_size+<span class="built_in">length</span>(test_data),<span class="number">1</span>), test_data, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;LineWidth&#x27;</span>, <span class="number">1</span>); <span class="built_in">hold</span> on<span class="comment">% 绘制测试集数据</span></span><br><span class="line"><span class="built_in">plot</span>(data(train_size+<span class="number">1</span>,<span class="number">1</span>):data(train_size+num_steps,<span class="number">1</span>), forecast, <span class="string">&#x27;r&#x27;</span>, <span class="string">&#x27;LineWidth&#x27;</span>, <span class="number">1</span>);<span class="built_in">hold</span> on <span class="comment">% 绘制预测数据</span></span><br><span class="line"> </span><br><span class="line">xlim([data(<span class="number">1</span>,<span class="number">1</span>), data(<span class="built_in">length</span>(time_series_data),<span class="number">1</span>)]);</span><br><span class="line">title(<span class="string">&#x27;ARIMA 时间序列预测&#x27;</span>);</span><br><span class="line">xlabel(<span class="string">&#x27;时间&#x27;</span>);</span><br><span class="line">ylabel(<span class="string">&#x27;值&#x27;</span>);</span><br><span class="line"><span class="built_in">legend</span>(<span class="string">&#x27;实际数据&#x27;</span>, <span class="string">&#x27;测试集数据&#x27;</span>, <span class="string">&#x27;预测&#x27;</span>, <span class="string">&#x27;Location&#x27;</span>, <span class="string">&#x27;best&#x27;</span>);</span><br><span class="line"> </span><br><span class="line"><span class="comment">% 10. 输出模型参数</span></span><br><span class="line"><span class="built_in">disp</span>([<span class="string">&#x27;最优模型参数: p = &#x27;</span>, num2str(best_p), <span class="string">&#x27;, d = &#x27;</span>, num2str(best_d), <span class="string">&#x27;, q = &#x27;</span>, num2str(best_q)]);</span><br><span class="line"><span class="built_in">disp</span>([<span class="string">&#x27;最小 AIC: &#x27;</span>, num2str(min_aic)]);</span><br><span class="line"><span class="built_in">disp</span>([<span class="string">&#x27;最小 BIC: &#x27;</span>, num2str(min_bic)]);</span><br></pre></td></tr></table></figure>
<p>灰色预测（GM）</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line">clc;clear;</span><br><span class="line"><span class="comment">%% 1.将原始数据进行累加，形成有规律的数据列</span></span><br><span class="line">syms a u;<span class="comment">%创建符号标量变量a和u</span></span><br><span class="line">c=[a,u]&#x27;;<span class="comment">%构成矩阵</span></span><br><span class="line">A=[<span class="number">15</span> <span class="number">16.1</span> <span class="number">17.3</span> <span class="number">18.4</span> <span class="number">18.7</span> <span class="number">19.6</span> <span class="number">19.9</span> <span class="number">21.3</span> <span class="number">22.5</span>];<span class="comment">%输入数据，可以修改</span></span><br><span class="line">Ago=cumsum(A);<span class="comment">%原始数据一次累加,得到1-AGO序列xi(1)。</span></span><br><span class="line"><span class="comment">%如果A是一个向量，cumsum(A)返回一个向量，该向量中第m行的元素是A中第1行到第m行的所有元素累加和；</span></span><br><span class="line"><span class="comment">%如果A是一个矩阵，cumsum(A)返回一个和A同行同列的矩阵，矩阵中第m行第n列元素是A中第1行到第m行的所有第n列元素的累加和；</span></span><br><span class="line"></span><br><span class="line"><span class="comment">%% 2.对累加数列进行平滑，生成均值序列，取α为0.5</span></span><br><span class="line">n=<span class="built_in">length</span>(A);<span class="comment">%原始数据个数</span></span><br><span class="line"><span class="keyword">for</span> k=<span class="number">1</span>:(n<span class="number">-1</span>)</span><br><span class="line">    Z(k)=(Ago(k)+Ago(k+<span class="number">1</span>))/<span class="number">2</span>; <span class="comment">%Z(i)为xi(1)的紧邻均值生成序列</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="comment">%% 3.利用最小二乘法求解参数a和u</span></span><br><span class="line">Yn = A;<span class="comment">%Yn为常数项向量</span></span><br><span class="line">Yn(<span class="number">1</span>)=[]; <span class="comment">%从第二个数开始，即x(2),x(3)...</span></span><br><span class="line">Yn=Yn&#x27;;</span><br><span class="line">E=[-Z;<span class="built_in">ones</span>(<span class="number">1</span>,n<span class="number">-1</span>)]&#x27;;<span class="comment">%累加生成数据做均值</span></span><br><span class="line">c=(E&#x27;*E)\(E&#x27;*Yn);<span class="comment">%利用公式求出a，u</span></span><br><span class="line"><span class="comment">%左除：a\b表示矩阵a的逆乘以b。右除：a/b表示矩阵a乘以矩阵b的逆</span></span><br><span class="line">c= c&#x27;;</span><br><span class="line">a=c(<span class="number">1</span>)<span class="comment">%得到a的值</span></span><br><span class="line">u=c(<span class="number">2</span>)<span class="comment">%得到u的值</span></span><br><span class="line"></span><br><span class="line"><span class="comment">%% 4.求解累加序列</span></span><br><span class="line">F=[];</span><br><span class="line">F(<span class="number">1</span>)=A(<span class="number">1</span>);</span><br><span class="line"><span class="keyword">for</span> k=<span class="number">2</span>:n</span><br><span class="line">    F(k)=(A(<span class="number">1</span>)-u/a)/<span class="built_in">exp</span>(a*(k<span class="number">-1</span>))+u/a;<span class="comment">%求出GM(1,1)模型公式</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="comment">%% 5.还原成原序列即得到预测函数</span></span><br><span class="line">G=[];</span><br><span class="line">G(<span class="number">1</span>)=A(<span class="number">1</span>);</span><br><span class="line"><span class="keyword">for</span> k=<span class="number">2</span>:n</span><br><span class="line">    G(k)=F(k)-F(k<span class="number">-1</span>);<span class="comment">%两者做差还原原序列，得到预测数据</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="comment">%% 6.可视化结果</span></span><br><span class="line">t1=<span class="number">1</span>:n;</span><br><span class="line">t2=<span class="number">1</span>:n;</span><br><span class="line"><span class="built_in">plot</span>(t1,A,<span class="string">&#x27;bo--&#x27;</span>);</span><br><span class="line"><span class="built_in">hold</span> on;</span><br><span class="line"><span class="built_in">plot</span>(t2,G,<span class="string">&#x27;r*-&#x27;</span>); </span><br><span class="line">title(<span class="string">&#x27;预测结果&#x27;</span>);</span><br><span class="line"><span class="built_in">legend</span>(<span class="string">&#x27;真实值&#x27;</span>,<span class="string">&#x27;预测值&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">%% 7.模型检验</span></span><br><span class="line">e=A-G;<span class="comment">%误差</span></span><br><span class="line">q=e/A;<span class="comment">%相对误差</span></span><br><span class="line">s1=var(A);<span class="comment">%方差</span></span><br><span class="line">s2=var(e);<span class="comment">%残差的方差</span></span><br><span class="line">c=s2/s1<span class="comment">%后验差比值</span></span><br><span class="line">len=<span class="built_in">length</span>(e);</span><br><span class="line">p=<span class="number">0</span>;  <span class="comment">%小误差概率</span></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:len</span><br><span class="line">    <span class="keyword">if</span>(<span class="built_in">abs</span>(e(<span class="built_in">i</span>))&lt;<span class="number">0.6745</span>*s1)</span><br><span class="line">        p=p+<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">p=p/len</span><br><span class="line"><span class="comment">% 好 P&gt;0.95 C&lt;0.35</span></span><br><span class="line"><span class="comment">% 合格 P&gt;0.80 C&lt;0.45</span></span><br><span class="line"><span class="comment">% 勉强合格 P&gt;0.70 C&lt;0.50</span></span><br><span class="line"><span class="comment">% 不合格 P&lt;=0.70 C&gt;=0.65</span></span><br></pre></td></tr></table></figure>
<h3 id="3-9-机器学习模型算法">3-9 机器学习模型算法</h3>
<p>Logistic回归</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line">clear</span><br><span class="line">clc</span><br><span class="line"><span class="comment">%% 1.数据准备</span></span><br><span class="line"><span class="comment">%二分类 随机生成数据。  200个数据  每个数据2个特征</span></span><br><span class="line">data=<span class="number">1</span>*<span class="built_in">rand</span>(<span class="number">300</span>,<span class="number">2</span>);<span class="comment">%生成300个0~1之间（开环，不包含0和1两个数）均匀分布的伪随机数</span></span><br><span class="line">label=<span class="built_in">zeros</span>(<span class="number">300</span>,<span class="number">1</span>);</span><br><span class="line"><span class="comment">%label(sqrt(data(:,1).^2+data(:,2).^2)&lt;8)=1;</span></span><br><span class="line">label((data(:,<span class="number">2</span>)+data(:,<span class="number">1</span>)&gt;<span class="number">1</span>))=<span class="number">1</span>;</span><br><span class="line"><span class="comment">%在data上加常数特征项；</span></span><br><span class="line">data=[data,<span class="built_in">ones</span>(<span class="built_in">size</span>(data,<span class="number">1</span>),<span class="number">1</span>)];<span class="comment">%size(A,1)该语句返回的时矩阵A的行数</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">%打乱顺序</span></span><br><span class="line">randIndex = randperm(<span class="built_in">size</span>(data,<span class="number">1</span>));<span class="comment">%返回一行包含从1到n的整数</span></span><br><span class="line">data_new=data(randIndex,:);</span><br><span class="line">label_new=label(randIndex,:);</span><br><span class="line"> </span><br><span class="line"><span class="comment">%80%训练  20%测试</span></span><br><span class="line">k=<span class="number">0.8</span>*<span class="built_in">size</span>(data,<span class="number">1</span>);</span><br><span class="line">X1=data_new(<span class="number">1</span>:k,:);</span><br><span class="line">Y1=label_new(<span class="number">1</span>:k,:);</span><br><span class="line">X2=data_new(k+<span class="number">1</span>:<span class="keyword">end</span>,:);</span><br><span class="line">Y2=label_new(k+<span class="number">1</span>:<span class="keyword">end</span>,:);</span><br><span class="line"> </span><br><span class="line">[m1,n1] = <span class="built_in">size</span>(X1);</span><br><span class="line">[m2,n2] = <span class="built_in">size</span>(X2);</span><br><span class="line">Features=<span class="built_in">size</span>(data,<span class="number">2</span>);<span class="comment">%特征个数</span></span><br><span class="line"><span class="comment">%% 2.开始训练</span></span><br><span class="line"><span class="comment">%设定学习率为1</span></span><br><span class="line">delta=<span class="number">1</span>;  </span><br><span class="line">theta1=<span class="built_in">rand</span>(<span class="number">1</span>,Features);</span><br><span class="line"><span class="comment">%theta1=[.5,.5];</span></span><br><span class="line"><span class="comment">%%训练模型</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">%梯度下降算法求解theta（每次都是对全部的数据进行训练）</span></span><br><span class="line">num = <span class="number">300</span>; <span class="comment">%最大迭代次数</span></span><br><span class="line">L=[];</span><br><span class="line"><span class="keyword">while</span>(num)</span><br><span class="line">    dt=<span class="built_in">zeros</span>(<span class="number">1</span>,Features);</span><br><span class="line">    loss=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:m1    <span class="comment">%训练集数据量</span></span><br><span class="line">        xx=X1(<span class="built_in">i</span>,<span class="number">1</span>:Features); </span><br><span class="line">        yy=Y1(<span class="built_in">i</span>,<span class="number">1</span>);</span><br><span class="line">        h=<span class="number">1</span>/(<span class="number">1</span>+<span class="built_in">exp</span>(-(theta1 * xx&#x27;)));  <span class="comment">%得到预测值</span></span><br><span class="line">        dt=dt+(h-yy) * xx;   <span class="comment">%计算梯度</span></span><br><span class="line">        loss=loss+ yy*<span class="built_in">log</span>(h)+(<span class="number">1</span>-yy)*<span class="built_in">log</span>(<span class="number">1</span>-h);</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">    loss=-loss/m1;<span class="comment">%计算风险函数的值</span></span><br><span class="line">    L=[L,loss];</span><br><span class="line">     </span><br><span class="line">    theta2=theta1 - delta*dt/m1;</span><br><span class="line">    theta1=theta2;</span><br><span class="line">    num = num - <span class="number">1</span>;</span><br><span class="line">     </span><br><span class="line">    <span class="keyword">if</span> loss&lt;<span class="number">0.01</span>   <span class="comment">%误差小到一定程度跳出循环</span></span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">theta1</span><br><span class="line"><span class="comment">%% 3.可视化结果</span></span><br><span class="line"><span class="built_in">figure</span></span><br><span class="line">subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line"><span class="built_in">plot</span>(L)</span><br><span class="line">title(<span class="string">&#x27;loss&#x27;</span>)</span><br><span class="line"> </span><br><span class="line">subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">x=<span class="number">0</span>:<span class="number">0.1</span>:<span class="number">10</span>;</span><br><span class="line">y=(-theta1(<span class="number">1</span>)*x-theta1(<span class="number">3</span>))/theta1(<span class="number">2</span>);</span><br><span class="line"><span class="built_in">plot</span>(x,y,<span class="string">&#x27;linewidth&#x27;</span>,<span class="number">2</span>)</span><br><span class="line"><span class="built_in">hold</span> on</span><br><span class="line"><span class="built_in">plot</span>(data(label==<span class="number">1</span>,<span class="number">1</span>),data(label==<span class="number">1</span>,<span class="number">2</span>),<span class="string">&#x27;ro&#x27;</span>)</span><br><span class="line"><span class="built_in">hold</span> on</span><br><span class="line"><span class="built_in">plot</span>(data(label==<span class="number">0</span>,<span class="number">1</span>),data(label==<span class="number">0</span>,<span class="number">2</span>),<span class="string">&#x27;go&#x27;</span>)</span><br><span class="line">axis([<span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span>])</span><br><span class="line"> </span><br><span class="line"><span class="comment">%% 4.测试数据</span></span><br><span class="line">acc=<span class="number">0</span>;</span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:m2</span><br><span class="line">    xx=X2(<span class="built_in">i</span>,<span class="number">1</span>:Features)&#x27;;</span><br><span class="line">    yy=Y2(<span class="built_in">i</span>);</span><br><span class="line">    finil=<span class="number">1</span>/(<span class="number">1</span>+<span class="built_in">exp</span>(-theta2 * xx));</span><br><span class="line">    <span class="keyword">if</span> finil&gt;<span class="number">0.5</span> &amp;&amp; yy==<span class="number">1</span></span><br><span class="line">        acc=acc+<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">    <span class="keyword">if</span> finil&lt;=<span class="number">0.5</span> &amp;&amp; yy==<span class="number">0</span></span><br><span class="line">        acc=acc+<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">acc/m2</span><br></pre></td></tr></table></figure>
<p>BP神经网络</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">close all; clearvars; clear; <span class="comment">%清空工作环境</span></span><br><span class="line">data = readmatrix(<span class="string">&#x27;sj1.xlsx&#x27;</span>);</span><br><span class="line">P = data(:,<span class="number">1</span>)&#x27;;</span><br><span class="line">T = data(:,<span class="number">2</span>)&#x27;;</span><br><span class="line"><span class="comment">%由于feedforwardnet函数自动对样本进行归一化和划分训练、验证、测试集,所以就不用手动将数据进行归一化处理，但不知道有没有打乱顺序</span></span><br><span class="line"><span class="comment">% net = feedforwardnet(5, &#x27;traingd&#x27;); %是&#x27;5&#x27;是指隐含层有5个神经元，这里只有一个隐含层，多个隐含层神经元的个数设置为[5,3,...]</span></span><br><span class="line">net = feedforwardnet([<span class="number">10</span>,<span class="number">5</span>], <span class="string">&#x27;traingd&#x27;</span>);<span class="comment">%两层隐含层，相应神经元个数分别为10和5</span></span><br><span class="line"><span class="comment">%traingd---梯度下降反向传播算法训练函数; traingda---自适应调整学习率的梯度下降反向传播算法训练函数；trainlm--- 中型网络，,内存需求最大,收敛速度最快</span></span><br><span class="line">net.trainParam.lr = <span class="number">0.01</span>; <span class="comment">%学习速率</span></span><br><span class="line">net.trainParam.epochs = <span class="number">1000</span>; <span class="comment">%最大训练次数</span></span><br><span class="line">net.trainParam.goal = <span class="number">1e-6</span>; <span class="comment">%最小误差，达到该精度，停止训练</span></span><br><span class="line">net.trainParam.show = <span class="number">50</span>; <span class="comment">%每50次展示训练结果</span></span><br><span class="line">net = train(net, P, T); <span class="comment">%net：需要训练的神经网络，P：网络输入，T：网络期望输出，并输出训练好的神经网络</span></span><br><span class="line">Y = net(P); <span class="comment">%计算预测值</span></span><br><span class="line">perf = perform(net, Y, T);<span class="comment">%计算误差性能</span></span><br><span class="line"><span class="built_in">plot</span>(P, T, <span class="string">&#x27;r-&#x27;</span>);<span class="built_in">hold</span> on</span><br><span class="line"><span class="built_in">plot</span>(P, Y ,<span class="string">&#x27;b-&#x27;</span>);<span class="built_in">hold</span> on</span><br></pre></td></tr></table></figure>
<p>LSTM预测</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><span class="line">close all; clearvars; clear; <span class="comment">%清空工作环境</span></span><br><span class="line">load XTrain;</span><br><span class="line">load XTest;</span><br><span class="line">load YTrain;</span><br><span class="line">load YTest;</span><br><span class="line"><span class="comment">%% 1.数据标准化</span></span><br><span class="line">XTrain_mu = <span class="built_in">mean</span>([XTrain&#123;:&#125;],<span class="number">2</span>); <span class="comment">%求均值</span></span><br><span class="line">XTrain_sig = std([XTrain&#123;:&#125;],<span class="number">0</span>,<span class="number">2</span>); <span class="comment">%求标准差</span></span><br><span class="line">XTest_mu = <span class="built_in">mean</span>([XTest&#123;:&#125;],<span class="number">2</span>);</span><br><span class="line">XTest_sig = std([XTest&#123;:&#125;],<span class="number">0</span>,<span class="number">2</span>);</span><br><span class="line">YTrain_mu = <span class="built_in">mean</span>([YTrain&#123;:&#125;],<span class="number">2</span>);</span><br><span class="line">YTrain_sig = std([YTrain&#123;:&#125;],<span class="number">0</span>,<span class="number">2</span>);</span><br><span class="line">YTest_mu = <span class="built_in">mean</span>([YTest&#123;:&#125;],<span class="number">2</span>);</span><br><span class="line">YTest_sig = std([YTest&#123;:&#125;],<span class="number">0</span>,<span class="number">2</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>:<span class="built_in">numel</span>(XTrain)  <span class="comment">%返回数组A中元素个数</span></span><br><span class="line">    XTrain&#123;<span class="built_in">i</span>&#125; = (XTrain&#123;<span class="built_in">i</span>&#125; - XTrain_mu) ./ XTrain_sig ;</span><br><span class="line">    YTrain&#123;<span class="built_in">i</span>&#125;=(YTrain&#123;<span class="built_in">i</span>&#125; - YTrain_mu) ./ YTrain_sig;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>:<span class="built_in">numel</span>(XTest)</span><br><span class="line">    XTest&#123;<span class="built_in">i</span>&#125;=(XTest&#123;<span class="built_in">i</span>&#125; - XTest_mu) ./ XTest_sig;</span><br><span class="line">    YTest&#123;<span class="built_in">i</span>&#125;=(YTest&#123;<span class="built_in">i</span>&#125; - YTest_mu) ./ YTest_sig;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="comment">%% 2.定义网络结构</span></span><br><span class="line"><span class="comment">%创建一个 LSTM 网络，该网络包含一个具有 200 个隐藏单元的 LSTM 层，</span></span><br><span class="line"><span class="comment">%然后是一个大小为 50 的全连接层和一个丢弃概率为 0.5 的丢弃层。</span></span><br><span class="line">numResponses = <span class="built_in">size</span>(YTrain&#123;<span class="number">1</span>&#125;,<span class="number">1</span>);</span><br><span class="line">numHiddenUnits = <span class="number">200</span>;</span><br><span class="line">numFeatures=<span class="number">15</span>;</span><br><span class="line">layers = [ ...</span><br><span class="line">    sequenceInputLayer(numFeatures)</span><br><span class="line">    lstmLayer(numHiddenUnits,<span class="string">&#x27;OutputMode&#x27;</span>,<span class="string">&#x27;sequence&#x27;</span>) <span class="comment">%序列到序列回归</span></span><br><span class="line">    fullyConnectedLayer(<span class="number">50</span>)</span><br><span class="line">    dropoutLayer(<span class="number">0.5</span>)</span><br><span class="line">    fullyConnectedLayer(numResponses)</span><br><span class="line">    regressionLayer];</span><br><span class="line"><span class="comment">% 层级设置=[</span></span><br><span class="line"><span class="comment">% 序列输入层（特征数量）</span></span><br><span class="line"><span class="comment">% lstm层（隐藏单元个数,&#x27;输出模式&#x27;,&#x27;多对一&#x27;）</span></span><br><span class="line"><span class="comment">% 全连接层（目标个数）%目标个数即分类的类别数</span></span><br><span class="line"><span class="comment">% 创建丢弃层，丢弃层以给定的概率将输入元素随机设置为零</span></span><br><span class="line"><span class="comment">% 回归层计算回归任务的半均方误差损失]</span></span><br><span class="line"><span class="comment">%% 3.设定参数</span></span><br><span class="line"><span class="comment">%使用求解器 &quot;adam&quot;进行 90 轮训练。</span></span><br><span class="line"><span class="comment">%指定学习率为 0.01。要防止梯度爆炸，将梯度阈值设置为1。</span></span><br><span class="line"><span class="comment">%要使序列保持按长度排序，将 Shuffle 选项设置为 &quot;never&quot;。</span></span><br><span class="line"><span class="comment">%在图中显示训练进度并监控均方根误差 (RMSE) 度量</span></span><br><span class="line">maxEpochs = <span class="number">90</span>;</span><br><span class="line">options = trainingOptions(<span class="string">&#x27;adam&#x27;</span>, ...</span><br><span class="line">    <span class="string">&#x27;MaxEpochs&#x27;</span>,maxEpochs, ...</span><br><span class="line">    <span class="string">&#x27;InitialLearnRate&#x27;</span>,<span class="number">0.01</span>, ...</span><br><span class="line">    <span class="string">&#x27;GradientThreshold&#x27;</span>,<span class="number">1</span>, ...</span><br><span class="line">    <span class="string">&#x27;Shuffle&#x27;</span>,<span class="string">&#x27;never&#x27;</span>, ...</span><br><span class="line">    <span class="string">&#x27;Plots&#x27;</span>,<span class="string">&#x27;training-progress&#x27;</span>,...</span><br><span class="line">    <span class="string">&#x27;Verbose&#x27;</span>,<span class="number">0</span>);</span><br><span class="line"><span class="comment">% 选项 = 训练选项设置(&#x27;累加器&#x27;, ...</span></span><br><span class="line"><span class="comment">%     &#x27;最大训练轮次&#x27;,maxEpochs, ...</span></span><br><span class="line"><span class="comment">%     &#x27;最小步距&#x27;,miniBatchSize, ...</span></span><br><span class="line"><span class="comment">%     &#x27;序列长度&#x27;,&#x27;整个序列&#x27;, ...</span></span><br><span class="line"><span class="comment">%     &#x27;乱序&#x27;,&#x27;否&#x27;, ...</span></span><br><span class="line"><span class="comment">%     &#x27;画图&#x27;,&#x27;训练过程&#x27;, ...</span></span><br><span class="line"><span class="comment">%     &#x27;在命令窗口中显示训练进度信息&#x27;,否);</span></span><br><span class="line"></span><br><span class="line"><span class="comment">%% 4.模型训练</span></span><br><span class="line">net = trainNetwork(XTrain,YTrain,layers,options);</span><br><span class="line"></span><br><span class="line"><span class="comment">% net = trainNetwork(imds,layers,options) 为图像分类问题训练网络。图像数据存储区 imds存储输入的图像数据， layers定义网络体系结构，并 options定义训练选项。</span></span><br><span class="line"><span class="comment">% net = trainNetwork(ds,layers,options) 使用数据存储训练网络ds。对于具有多个输入的网络，请将此语法与组合或转换后的数据存储区结合使用。</span></span><br><span class="line"><span class="comment">% net = trainNetwork(X,Y,layers,options) 为图像分类和回归问题训练网络。数字数组X包含预测变量，并 Y包含分类标签或数字响应。</span></span><br><span class="line"><span class="comment">% net = trainNetwork(sequences,Y,layers,options) 训练网络以解决序列分类和回归问题（例如LSTM或BiLSTM网络），其中sequences 包含序列或时间序列预测变量并Y包含响应。对于分类问题，Y是分类向量或分类序列的单元格数组。对于回归问题，Y是目标矩阵或数字序列的单元格数组。</span></span><br><span class="line"><span class="comment">% net = trainNetwork(tbl,layers,options) 为分类和回归问题训练网络。该表 tbl包含数字数据或数据的文件路径。预测变量必须位于的第一列中tbl。有关目标或响应变量的信息，请参见tbl。</span></span><br><span class="line"><span class="comment">% net = trainNetwork(tbl,responseName,layers,options) 为分类和回归问题训练网络。预测变量必须位于的第一列中tbl。该 responseName参数指定在响应变量tbl。</span></span><br><span class="line"><span class="comment">% [net,info] = trainNetwork(___) 还可以使用先前语法中的任何输入参数返回有关训练的信息。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">%% 5.回归预测</span></span><br><span class="line">YPred = predict(net,XTest);<span class="comment">%将训练好的模型net和即将要预测的数据XTest输入，得到预测结果</span></span><br><span class="line"><span class="comment">%% 6.输出可视化</span></span><br><span class="line">idx = randperm(<span class="built_in">numel</span>(YPred),<span class="number">4</span>); <span class="comment">%随机输出4组预测数据</span></span><br><span class="line"><span class="built_in">figure</span></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>:<span class="built_in">numel</span>(idx)</span><br><span class="line">    subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="built_in">i</span>)</span><br><span class="line">    <span class="built_in">plot</span>(YTest&#123;idx(<span class="built_in">i</span>)&#125;,<span class="string">&#x27;--&#x27;</span>)</span><br><span class="line">    <span class="built_in">hold</span> on</span><br><span class="line">    <span class="built_in">plot</span>(YPred&#123;idx(<span class="built_in">i</span>)&#125;,<span class="string">&#x27;.-&#x27;</span>)</span><br><span class="line">    <span class="built_in">hold</span> off</span><br><span class="line">    title(<span class="string">&quot;Test Observation &quot;</span> + idx(<span class="built_in">i</span>))</span><br><span class="line">    xlabel(<span class="string">&quot;Time Step&quot;</span>)</span><br><span class="line">    ylabel(<span class="string">&quot;青霉素浓度&quot;</span>)</span><br><span class="line">    rmse = <span class="built_in">sqrt</span>(<span class="built_in">mean</span>((YPred&#123;<span class="built_in">i</span>&#125; - YTest&#123;<span class="built_in">i</span>&#125;).^<span class="number">2</span>)) <span class="comment">%求解均方根误差评估模型性能</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="built_in">legend</span>([<span class="string">&quot;True&quot;</span> <span class="string">&quot;Predicted&quot;</span>],<span class="string">&#x27;Location&#x27;</span>,<span class="string">&#x27;southeast&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>使用时需导入Xtrain.mat、Ytrain.mat</p>
<h3 id="3-10">3-10</h3>
<p>随机森林回归</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br></pre></td><td class="code"><pre><span class="line">close all  <span class="comment">%关闭开启图窗</span></span><br><span class="line">clear  <span class="comment">%清空变量</span></span><br><span class="line">clc    <span class="comment">%清空命令行</span></span><br><span class="line"><span class="comment">% rng(2222)  %随机数种子固定结果</span></span><br><span class="line">res =readmatrix(<span class="string">&#x27;sj3.xlsx&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">%% 数据归一化</span></span><br><span class="line">X = res(:,<span class="number">1</span>:<span class="keyword">end</span><span class="number">-1</span>);</span><br><span class="line">Y = res(:,<span class="keyword">end</span>);</span><br><span class="line">[x,psin] = mapminmax(X&#x27;,<span class="number">0</span>,<span class="number">1</span>);<span class="comment">%mapminmax对每一行进行规划，所以需要对X进行转置</span></span><br><span class="line">[y,psout] = mapminmax(Y&#x27;,<span class="number">0</span>,<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">%% 划分训练集和测试集</span></span><br><span class="line">num = <span class="built_in">size</span>(res,<span class="number">1</span>);<span class="comment">%总样本数</span></span><br><span class="line">state =randperm(num);<span class="comment">%打乱样本，提高泛化性</span></span><br><span class="line">ratio = <span class="number">0.7</span>;</span><br><span class="line">train_num = <span class="built_in">floor</span>(num*ratio);</span><br><span class="line"></span><br><span class="line">x_train = x(:,state(<span class="number">1</span>:train_num))&#x27;;<span class="comment">%工具箱需要每个特征竖着分布，因此需要转置</span></span><br><span class="line">y_train = y(state(<span class="number">1</span>:train_num))&#x27;;</span><br><span class="line">x_test = x(:,state(train_num+<span class="number">1</span>:<span class="keyword">end</span>))&#x27;;</span><br><span class="line">y_test = y(state(train_num+<span class="number">1</span>:<span class="keyword">end</span>))&#x27;;</span><br><span class="line"></span><br><span class="line"><span class="comment">%% 训练模型</span></span><br><span class="line">trees = <span class="number">100</span>;<span class="comment">%决策树数目</span></span><br><span class="line">leaf = <span class="number">3</span>;<span class="comment">%定义叶子节点个数，最小叶子数，过小容易拟合</span></span><br><span class="line">wuc = <span class="string">&#x27;on&#x27;</span>;<span class="comment">%打开误差图</span></span><br><span class="line">Importance = <span class="string">&#x27;on&#x27;</span>;<span class="comment">%计算特征重要性</span></span><br><span class="line"><span class="comment">%regression——回归</span></span><br><span class="line">net = TreeBagger(trees,x_train,y_train,<span class="string">&#x27;OOBPredictorImportance&#x27;</span>,Importance,...</span><br><span class="line">    <span class="string">&#x27;Method&#x27;</span>,<span class="string">&#x27;regression&#x27;</span>,<span class="string">&#x27;OOBPrediction&#x27;</span>,wuc,<span class="string">&#x27;minleaf&#x27;</span>,leaf);</span><br><span class="line">import = net.OOBPermutedPredictorDeltaError;</span><br><span class="line"></span><br><span class="line"><span class="comment">%% 预测</span></span><br><span class="line">re1 = predict(net , x_train);</span><br><span class="line">re2 = predict(net , x_test);</span><br><span class="line"></span><br><span class="line"><span class="comment">%% 数据反归一化</span></span><br><span class="line"><span class="comment">%实际值</span></span><br><span class="line">Y_train = Y(state(<span class="number">1</span>:train_num));</span><br><span class="line">Y_test = Y(state(train_num+<span class="number">1</span>:<span class="keyword">end</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">%预测值</span></span><br><span class="line">pre1 = mapminmax(<span class="string">&#x27;reverse&#x27;</span>,re1,psout);</span><br><span class="line">pre2 = mapminmax(<span class="string">&#x27;reverse&#x27;</span>,re2,psout);</span><br><span class="line"><span class="comment">%%</span></span><br><span class="line"><span class="comment">%均方根误差</span></span><br><span class="line">error1 = <span class="built_in">sqrt</span>(<span class="built_in">mean</span>(pre1 - Y_train).^<span class="number">2</span>);</span><br><span class="line">error2 = <span class="built_in">sqrt</span>(<span class="built_in">mean</span>(pre2 - Y_test).^<span class="number">2</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">%相关指标计算</span></span><br><span class="line"><span class="comment">%R2</span></span><br><span class="line">R1 = <span class="number">1</span> - norm(Y_train - pre1)^<span class="number">2</span> / norm(Y_train -  <span class="built_in">mean</span>(Y_train))^<span class="number">2</span>;</span><br><span class="line">R2 = <span class="number">1</span> - norm(Y_test - pre2)^<span class="number">2</span> / norm(Y_test -  <span class="built_in">mean</span>(Y_test))^<span class="number">2</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">%MAE</span></span><br><span class="line">mae1 = <span class="built_in">mean</span>(<span class="built_in">abs</span>(Y_train - pre1));</span><br><span class="line">mae2 = <span class="built_in">mean</span>(<span class="built_in">abs</span>(pre2 - Y_test));</span><br><span class="line"></span><br><span class="line"><span class="built_in">disp</span>(<span class="string">&#x27;训练集预测精度指标如下：&#x27;</span>)</span><br><span class="line"><span class="built_in">disp</span>([<span class="string">&#x27;训练集的R2：&#x27;</span>,num2str(R1)])</span><br><span class="line"><span class="built_in">disp</span>([<span class="string">&#x27;训练集的MAE：&#x27;</span>,num2str(mae1)])</span><br><span class="line"><span class="built_in">disp</span>([<span class="string">&#x27;训练集的RMSE：&#x27;</span>,num2str(error1)])</span><br><span class="line"><span class="built_in">disp</span>(<span class="string">&#x27;测试集预测精度指标如下：&#x27;</span>)</span><br><span class="line"><span class="built_in">disp</span>([<span class="string">&#x27;测试集的R2：&#x27;</span>,num2str(R2)])</span><br><span class="line"><span class="built_in">disp</span>([<span class="string">&#x27;测试集的MAE：&#x27;</span>,num2str(mae2)])</span><br><span class="line"><span class="built_in">disp</span>([<span class="string">&#x27;测试集的RMSE：&#x27;</span>,num2str(error2)])</span><br><span class="line"><span class="comment">%%</span></span><br><span class="line"><span class="built_in">figure</span></span><br><span class="line"><span class="built_in">plot</span>(<span class="number">1</span>:train_num,Y_train,<span class="string">&#x27;r-O&#x27;</span>,<span class="number">1</span>:train_num,pre1,<span class="string">&#x27;b-+&#x27;</span>,<span class="string">&#x27;LineWidth&#x27;</span>,<span class="number">1</span>)</span><br><span class="line"><span class="built_in">legend</span>(<span class="string">&#x27;真实值&#x27;</span>,<span class="string">&#x27;预测值&#x27;</span>)</span><br><span class="line">xlabel(<span class="string">&#x27;样本点&#x27;</span>)</span><br><span class="line">ylabel(<span class="string">&#x27;预测值&#x27;</span>)</span><br><span class="line">title(<span class="string">&#x27;训练集预测结果对比&#x27;</span>)</span><br><span class="line"><span class="built_in">figure</span></span><br><span class="line"><span class="built_in">plot</span>(<span class="number">1</span>:num-train_num,Y_test,<span class="string">&#x27;r-O&#x27;</span>,<span class="number">1</span>:num-train_num,pre2,<span class="string">&#x27;b-+&#x27;</span>,<span class="string">&#x27;LineWidth&#x27;</span>,<span class="number">1</span>)</span><br><span class="line"><span class="built_in">legend</span>(<span class="string">&#x27;真实值&#x27;</span>,<span class="string">&#x27;预测值&#x27;</span>)</span><br><span class="line">xlabel(<span class="string">&#x27;样本点&#x27;</span>)</span><br><span class="line">ylabel(<span class="string">&#x27;预测值&#x27;</span>)</span><br><span class="line">title(<span class="string">&#x27;测试集预测结果对比&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">%% 绘制误差曲线</span></span><br><span class="line"><span class="built_in">figure</span></span><br><span class="line"><span class="built_in">plot</span>(<span class="number">1</span>:trees,oobError(net),<span class="string">&#x27;r--O&#x27;</span>,<span class="string">&#x27;LineWidth&#x27;</span>,<span class="number">1</span>)</span><br><span class="line"><span class="built_in">legend</span>(<span class="string">&#x27;误差迭代曲线&#x27;</span>)</span><br><span class="line">xlabel(<span class="string">&#x27;决策树（迭代次数）&#x27;</span>)</span><br><span class="line">ylabel(<span class="string">&#x27;误差&#x27;</span>)</span><br><span class="line">grid</span><br><span class="line"><span class="comment">%% 绘制重要性</span></span><br><span class="line"><span class="built_in">figure</span></span><br><span class="line">bar(import,<span class="string">&#x27;green&#x27;</span>)</span><br><span class="line">yticks([])</span><br><span class="line">xlabel(<span class="string">&#x27;特征&#x27;</span>)</span><br><span class="line">ylabel(<span class="string">&#x27;重要性&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">%% 新数据预测</span></span><br><span class="line"><span class="comment">% newdata = xlsread(&quot;新的多输入&quot;);</span></span><br><span class="line"><span class="comment">% newy = newpre(newdata,psin,psout,net);</span></span><br><span class="line"><span class="comment">% figure</span></span><br><span class="line"><span class="comment">% plot(newy)</span></span><br><span class="line"><span class="comment">% xlabel(&#x27;样本点&#x27;)</span></span><br><span class="line"><span class="comment">% ylabel(&#x27;预测值&#x27;)</span></span><br><span class="line"><span class="comment">% xlswrite(&quot;新的输出&quot;,newy)</span></span><br><span class="line"><span class="comment">% </span></span><br><span class="line"><span class="comment">% function y = newpre(newdata,psin,psout,net)</span></span><br><span class="line"><span class="comment">%    x = mapminmax(&#x27;apply&#x27;,newdata&#x27;,psin);</span></span><br><span class="line"><span class="comment">%    pre = predict(net,x&#x27;);</span></span><br><span class="line"><span class="comment">%    y = mapminmax(&#x27;reverse&#x27;,pre,psout);</span></span><br><span class="line"><span class="comment">% end</span></span><br></pre></td></tr></table></figure>
</article><div class="tag_share"><div class="post_share"><div class="social-share" data-image="https://s1.ax1x.com/2023/01/05/pSAEFZd.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/post/2024%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%AB%9E%E8%B5%9BA%E9%A2%98.html"><img class="prev-cover" src="https://s1.ax1x.com/2023/01/05/pSAEFZd.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">2024数学建模竞赛A题</div></div></a></div><div class="next-post pull-right"><a href="/post/%E6%80%BB%E7%BB%93.html"><img class="next-cover" src="https://s1.ax1x.com/2023/01/05/pSAEFZd.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">数模课第一次小组讨论</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://s1.ax1x.com/2023/01/05/pSAFoF0.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">浩月当空</div><div class="author-info__description">快跑，不要对这个大坑感兴趣</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">30</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">19</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">17</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://qm.qq.com/cgi-bin/qm/qr?k=p2mOZuoekn7vgrUB4RCbfTtS-WNoiQ7t&amp;noverify=0"><i class="fa-brands fa-qq"></i><span>联系我</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">欢迎联系我！<br />QQ:3583630940</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%98%E5%9B%BE%E7%B1%BB"><span class="toc-number">1.</span> <span class="toc-text">绘图类</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#python%E7%BB%98%E5%9B%BE"><span class="toc-number">1.1.</span> <span class="toc-text">python绘图</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8A%98%E7%BA%BF%E5%9B%BE"><span class="toc-number">1.1.1.</span> <span class="toc-text">折线图</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%A3%E7%82%B9%E5%9B%BE"><span class="toc-number">1.1.2.</span> <span class="toc-text">散点图</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%A5%BC%E5%9B%BE"><span class="toc-number">1.1.3.</span> <span class="toc-text">饼图</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E5%92%8C%E7%AE%97%E6%B3%95%E5%86%85%E5%AE%B9"><span class="toc-number">2.</span> <span class="toc-text">数据处理和算法内容</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-%E7%86%B5%E6%9D%83%E6%B3%95"><span class="toc-number">2.1.</span> <span class="toc-text">3-1 熵权法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-%E6%94%B9%E8%BF%9B%E6%A8%A1%E6%8B%9F%E9%80%80%E7%81%AB%E7%AE%97%E6%B3%95"><span class="toc-number">2.2.</span> <span class="toc-text">3-3 改进模拟退火算法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-%E6%97%85%E8%A1%8C%E5%95%86%E9%97%AE%E9%A2%98"><span class="toc-number">2.3.</span> <span class="toc-text">3-3 旅行商问题</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-%E7%B2%92%E5%AD%90%E7%BE%A4"><span class="toc-number">2.4.</span> <span class="toc-text">3-3 粒子群</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95"><span class="toc-number">2.5.</span> <span class="toc-text">3-3 遗传算法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-4-%E5%9B%BE%E8%AE%BA%E4%B8%8E%E8%B7%AF%E5%BE%84"><span class="toc-number">2.6.</span> <span class="toc-text">3-4 图论与路径</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-5-%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.7.</span> <span class="toc-text">3-5 回归模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-6-%E6%9C%89%E7%9B%91%E7%9D%A3%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.8.</span> <span class="toc-text">3-6 有监督分类模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-7-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95"><span class="toc-number">2.9.</span> <span class="toc-text">3-7 无监督分类算法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.10.</span> <span class="toc-text">时间序列模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-9-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95"><span class="toc-number">2.11.</span> <span class="toc-text">3-9 机器学习模型算法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-10"><span class="toc-number">2.12.</span> <span class="toc-text">3-10</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/post/2024%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%AB%9E%E8%B5%9BA%E9%A2%98.html" title="2024数学建模竞赛A题"><img src="https://s1.ax1x.com/2023/01/05/pSAEFZd.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="2024数学建模竞赛A题"/></a><div class="content"><a class="title" href="/post/2024%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%AB%9E%E8%B5%9BA%E9%A2%98.html" title="2024数学建模竞赛A题">2024数学建模竞赛A题</a><time datetime="2024-09-07T16:00:00.000Z" title="发表于 2024-09-08 00:00:00">2024-09-08</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/post/%E6%95%B0%E6%A8%A1%E4%BB%A3%E7%A0%81%E6%95%B4%E7%90%86.html" title="数模代码整理"><img src="https://s1.ax1x.com/2023/01/05/pSAEFZd.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="数模代码整理"/></a><div class="content"><a class="title" href="/post/%E6%95%B0%E6%A8%A1%E4%BB%A3%E7%A0%81%E6%95%B4%E7%90%86.html" title="数模代码整理">数模代码整理</a><time datetime="2024-08-31T16:00:00.000Z" title="发表于 2024-09-01 00:00:00">2024-09-01</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/post/%E6%80%BB%E7%BB%93.html" title="数模课第一次小组讨论"><img src="https://s1.ax1x.com/2023/01/05/pSAEFZd.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="数模课第一次小组讨论"/></a><div class="content"><a class="title" href="/post/%E6%80%BB%E7%BB%93.html" title="数模课第一次小组讨论">数模课第一次小组讨论</a><time datetime="2024-07-13T16:00:00.000Z" title="发表于 2024-07-14 00:00:00">2024-07-14</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/post/EGO1%E5%BC%80%E5%8F%91%E6%9D%BF%E5%AE%9E%E7%8E%B0%E5%85%AB%E4%BD%8D%E6%95%B0%E7%A0%81%E7%AE%A1%E6%98%BE%E7%A4%BA.html" title="EGO1开发板实现八位数码管显示"><img src="https://s1.ax1x.com/2023/01/05/pSAEFZd.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="EGO1开发板实现八位数码管显示"/></a><div class="content"><a class="title" href="/post/EGO1%E5%BC%80%E5%8F%91%E6%9D%BF%E5%AE%9E%E7%8E%B0%E5%85%AB%E4%BD%8D%E6%95%B0%E7%A0%81%E7%AE%A1%E6%98%BE%E7%A4%BA.html" title="EGO1开发板实现八位数码管显示">EGO1开发板实现八位数码管显示</a><time datetime="2024-05-02T16:00:00.000Z" title="发表于 2024-05-03 00:00:00">2024-05-03</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/post/TM4C123G%E5%8D%95%E7%89%87%E6%9C%BA%E5%8F%8ACCS.html" title="TM4C123G单片机及CCS"><img src="https://s21.ax1x.com/2024/03/24/pF4P50P.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="TM4C123G单片机及CCS"/></a><div class="content"><a class="title" href="/post/TM4C123G%E5%8D%95%E7%89%87%E6%9C%BA%E5%8F%8ACCS.html" title="TM4C123G单片机及CCS">TM4C123G单片机及CCS</a><time datetime="2024-03-23T16:00:00.000Z" title="发表于 2024-03-24 00:00:00">2024-03-24</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2022 - 2024 By 浩月当空</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">做学问一定要严谨！</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><div class="js-pjax"></div><script src="/js/line_background.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>